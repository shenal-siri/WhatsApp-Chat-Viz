{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Chat History Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: This is a work-in-progress notebook for prototyping my chat log data visualization tool. Code here has been minimally refactored / vectorized / optimized and therefore has plenty of scope for improvement!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by importing our bread-and-butter data and visualization libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the custom dictionaries defined in `Chat-History-Custom-Functs.ipynb` (which will be used in the text normalization process). Feel free to edit the dictionaries based on the desired normalization in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Chat-History-User-Defined.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the WhatsApp chat log (exported from an iOS device) to a dataframe and make a deepcopy for us to try out all of our preprocessing on. <br>\n",
    "**Note:** For privacy purposes, the chat log available on GitHub is much shorter and consists of dummy text, albeit maintaining WhatsApp's export style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 1: From outside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 2: and lool lool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2020-02-28, 2:56:07 AM] User 2: \\ which told ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2020-02-28, 2:56:27 AM] User 1: ðŸ˜¯ Far away we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw\n",
       "0  [2020-02-28, 2:55:53 AM] User 1: From outside ...\n",
       "1  [2020-02-28, 2:55:53 AM] User 2: and lool lool...\n",
       "2  [2020-02-28, 2:56:07 AM] User 2: \\ which told ...\n",
       "3  [2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...\n",
       "4  [2020-02-28, 2:56:27 AM] User 1: ðŸ˜¯ Far away we..."
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Whatsapp chat log to a dataframe\n",
    "\n",
    "imported_messages = pd.read_csv('chat.txt', delimiter='\\n', skiprows=[0], names = ['text_raw'])\n",
    "imported_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[2020-03-08, 05:20:32 PM] User 2: At the momen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[2020-03-08, 05:45:56 PM] User 1: lool but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[2020-03-08, 05:50:34 PM] User 2: I could, how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[2020-03-08, 05:52:12 PM] User 2: https://towa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "29  [2020-03-08, 05:20:32 PM] User 2: At the momen...\n",
       "30  [2020-03-08, 05:45:56 PM] User 1: lool but the...\n",
       "31  made it impossible for me to tell what it was ...\n",
       "32  [2020-03-08, 05:50:34 PM] User 2: I could, how...\n",
       "33  [2020-03-08, 05:52:12 PM] User 2: https://towa..."
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Using '\\n' as the delimiter results in messages with embedded line breaks escaping to new rows in the dataframe. These rows will not have the '*\\[datetime\\] username: text*' pattern seen in other rows, so we need to handle these appropriately when separating out datetimes and usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2020-02-29, 6:00:23 PM] User 1: â˜º Twelve struck,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2020-02-29, 6:15:12 PM] User 1: â€Žvideo omitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "7   [2020-02-29, 6:00:23 PM] User 1: â˜º Twelve struck,\n",
       "8                          and one and two and three,\n",
       "9   and still we sat waiting silently for whatever...\n",
       "10    [2020-02-29, 6:15:12 PM] User 1: â€Žvideo omitted"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deepcopy into a working dataframe for preprocessing / cleaning\n",
    "\n",
    "messages = imported_messages.copy(deep=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Non-Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's work on extracting the datetime and username fields by leveraging [regular expressions](https://jakevdp.github.io/WhirlwindTourOfPython/14-strings-and-regular-expressions.html). Let's start with some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help us handle dates/times\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Library for regular expressions\n",
    "import regex\n",
    "\n",
    "# Library to handle emojis in text\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a helper function to aid us with extracting usernames and datetimes, then apply it to our dataframe. Here is further reading on [Regex Match Objects](https://docs.python.org/2.0/lib/match-objects.html) and [Python string splitting](https://docs.python.org/3/library/stdtypes.html#str.split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract datetime and username as text\n",
    "def extract_datetime_username(text):\n",
    "    \"\"\"\n",
    "    Note:   Requires regex module to be imported\n",
    "    Input:  String of text which may contain '[...]' text pattern\n",
    "            Eg: \"[2018-12-21, 2:55:51 AM] User 1: Messages to this chat and calls are now secured with end-to-end encryption.\"\n",
    "            \n",
    "    Output: Tuple of EITHER: (String to the right of the ': ' text pattern      Eg. \"Messages to this chat and calls are now secured with end-to-end encryption.\"\n",
    "                              String with contents of the '[...]' text pattern  Eg. \"2018-12-21, 2:55:51 AM\", \n",
    "                              String between the '[...]' and ': ' text patterns Eg. \"User 1\" )\n",
    "                              \n",
    "                     OR:     (String of of the original text if ''[...]'' pattern is not found,\n",
    "                              NaN,\n",
    "                              NaN)\n",
    "    \"\"\"\n",
    "    # Regex to find '[...]' pattern in text. date_time is a Regex Match Object\n",
    "    date_time = regex.search(r'.*\\[(.*)\\].*', text)\n",
    "    \n",
    "    # Output based on pattern search result\n",
    "    if date_time:\n",
    "        # Since we want to split only on the first occurrence of \"] \" and \": \" respectively, we pass in maxsplit=1 on str.split()\n",
    "        text_no_date = text.split(\"] \", maxsplit=1)[1]\n",
    "        text_split_on_user = text_no_date.split(\": \", maxsplit=1)\n",
    "        return (text_split_on_user[1], date_time.group(1), text_split_on_user[0])\n",
    "    else:\n",
    "        return (text, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28, 2:56:07 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28, 2:56:08 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28, 2:56:27 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw               date_time  \\\n",
       "0  From outside came the occasional cry of a nigh...  2020-02-28, 2:55:53 AM   \n",
       "1  and lool lool lool lool once at our very windo...  2020-02-28, 2:55:53 AM   \n",
       "2  \\ which told us that the cheetah was indeed at...  2020-02-28, 2:56:07 AM   \n",
       "3                                hah lmaoooo wooowww  2020-02-28, 2:56:08 AM   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...  2020-02-28, 2:56:27 AM   \n",
       "\n",
       "  username  \n",
       "0   User 1  \n",
       "1   User 2  \n",
       "2   User 2  \n",
       "3   User 2  \n",
       "4   User 1  "
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to our dataframe and extract out the datetimes and usernames\n",
    "messages['text_raw'], messages['date_time'], messages['username'] = zip(*messages['text_raw'].apply(extract_datetime_username))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>â˜º Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â€Žvideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    â˜º Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,                     NaN   \n",
       "9   and still we sat waiting silently for whatever...                     NaN   \n",
       "10                                     â€Žvideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8       NaN  \n",
       "9       NaN  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure functionality is as intended on rows with embedded line breaks\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's verify if there are any rows of text with none / NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_raw, date_time, username]\n",
       "Index: []"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['text_raw'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill in the NaN values in the 'date_time' and 'username' columns by considering those messages to have been sent by the user in the row above, at the time in the row above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>â˜º Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â€Žvideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    â˜º Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,  2020-02-29, 6:00:23 PM   \n",
       "9   and still we sat waiting silently for whatever...  2020-02-29, 6:00:23 PM   \n",
       "10                                     â€Žvideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8    User 1  \n",
       "9    User 1  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.fillna(method='ffill', inplace=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leverage Python's `datetime` module to convert our date_time column from a string to handy datetime objects (localized in my case to Toronto, Canada). <br>\n",
    "**Note:** Runtime on this appears to be abysmal, but performs acceptably on a sub 100k record dataset. This is probably a good area to attempt optimization later (Do we need expensive datetime objects? Do we need to localize? Which of the two methods is the bottleneck? Is there a better function other than df.apply()?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_TIMEZONE = timezone('America/Toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \n",
       "0 2020-02-28 02:55:53-05:00   User 1  \n",
       "1 2020-02-28 02:55:53-05:00   User 2  \n",
       "2 2020-02-28 02:56:07-05:00   User 2  \n",
       "3 2020-02-28 02:56:08-05:00   User 2  \n",
       "4 2020-02-28 02:56:27-05:00   User 1  "
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['date_time'] = messages['date_time'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d, %I:%M:%S %p'))\n",
    "messages['date_time'] = messages['date_time'].apply(lambda x: LOCAL_TIMEZONE.localize(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to work directly on the text data and make it more palatable for extracting insights from. We'll begin with library imports - primarily from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python String Library\n",
    "import string\n",
    "\n",
    "# NLTK for all our languarge processing needs (tokenization and stopword removal - lemmatization if our data ends up too 'muddy')\n",
    "import nltk\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "#from normalise import normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, let's outline what our [text preprocessing](https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html) pipeline will look like. <br><br>\n",
    "**Pipeline:**\n",
    "1. Tokenize each message\n",
    "2. Separate out emojis (**Note:** This might be revisited if/when I begin investigating sentiment analysis)                    \n",
    "3. Categorize each message type (text / picture / video / link)\n",
    "4. Clean text messages\n",
    "5. Normalize user-specific slang in text messages\n",
    "6. Remove stopwords from text messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:**<br>\n",
    "Let's [tokenize](https://www.geeksforgeeks.org/tokenize-text-using-nltk-python/) our corpus of text messages! In this case, we'll use NLTK's `TweetTokenizer`, since it is capable of splitting up emoji groupings and identifying html links as single tokens (see [here](https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7) for a brief comparison between NLTK tokenizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...  \n",
       "31  [made, it, impossible, for, me, to, tell, what...  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  \n",
       "33  [https://towardsdatascience.com/an-introductio...  "
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "messages['text_processed'] = messages['text_raw'].apply(lambda x: tokenizer.tokenize(x))\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** <br>\n",
    "Let's now extract out the emojis from the text - through a helper function defined below. This will simplify the workload involved in extracting out emoji-related insights in our visualizations down the line. <br><br>\n",
    "**Note:** I had originally modified a solution found [here](https://stackoverflow.com/questions/49113909/split-and-count-emojis-and-words-in-a-given-string-in-python?noredirect=1&lq=1) to create a (very un-optimized!) solution that extracted emojis directly from the un-tokenized messages. However, this was before I discovered the magic of `TweetTokenizer`!\n",
    "[This site](https://www.regular-expressions.info/) and [this post](https://stackoverflow.com/questions/9928505/what-does-the-expression-x-match-when-inside-a-regex)  provided a lot of insight into understanding and using regex (despite it not being needed as heavily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for separating out emojis from the tokenized corpus\n",
    "def extract_emojis(tokenlist):\n",
    "    \"\"\"\n",
    "    Input:  List of tokenized strings (utf-8), containing emojis \n",
    "    Output: Tuple of the following: (list of non-emoji tokens from the input, list of all emoji tokens from the input)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    list_emojis = []\n",
    "    list_text = []\n",
    "    \n",
    "    list_emojis = [token for token in tokenlist if any(char in emoji.UNICODE_EMOJI for char in token)]\n",
    "    list_text = [token for token in tokenlist if token not in list_emojis]\n",
    "    \n",
    "    return (list_text, list_emojis)\n",
    "\n",
    "#   **For reference, here's the original emoji list creation code without the one-liner list comprehension\n",
    "#    list_emojis = []\n",
    "#    for token in tokenlist:\n",
    "#        if any(char in emoji.UNICODE_EMOJI for char in token):  \n",
    "#            list_emojis += [token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>struck a match, and lashed furiously with his ...</td>\n",
       "      <td>2020-03-07 00:09:48-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[struck, a, match, ,, and, lashed, furiously, ...</td>\n",
       "      <td>[ðŸ˜†]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ðŸ˜¯ðŸ‘€</td>\n",
       "      <td>2020-03-07 00:09:56-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ‘€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"You see it, Watson?\" he yelled. \"You see it?\"</td>\n",
       "      <td>2020-03-08 17:10:08-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[\", You, see, it, ,, Watson, ?, \", he, yelled,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>But I saw nothing lmaoo. ðŸ˜¯</td>\n",
       "      <td>2020-03-08 17:10:29-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[But, I, saw, nothing, lmaoo, .]</td>\n",
       "      <td>[ðŸ˜¯]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>â€Žimage omitted</td>\n",
       "      <td>2020-03-08 17:15:24-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[â€Ž, image, omitted]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "24  struck a match, and lashed furiously with his ...   \n",
       "25                                                 ðŸ˜¯ðŸ‘€   \n",
       "26     \"You see it, Watson?\" he yelled. \"You see it?\"   \n",
       "27                         But I saw nothing lmaoo. ðŸ˜¯   \n",
       "28                                     â€Žimage omitted   \n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "24 2020-03-07 00:09:48-05:00   User 1   \n",
       "25 2020-03-07 00:09:56-05:00   User 1   \n",
       "26 2020-03-08 17:10:08-04:00   User 1   \n",
       "27 2020-03-08 17:10:29-04:00   User 1   \n",
       "28 2020-03-08 17:15:24-04:00   User 1   \n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis  \n",
       "24  [struck, a, match, ,, and, lashed, furiously, ...        [ðŸ˜†]  \n",
       "25                                                 []     [ðŸ˜¯, ðŸ‘€]  \n",
       "26  [\", You, see, it, ,, Watson, ?, \", he, yelled,...         []  \n",
       "27                   [But, I, saw, nothing, lmaoo, .]        [ðŸ˜¯]  \n",
       "28                                [â€Ž, image, omitted]         []  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...         []  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []  "
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe and extract out the emojis\n",
    "messages['text_processed'], messages['emojis'] = zip(*messages['text_processed'].apply(extract_emojis))\n",
    "messages.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**<br>\n",
    "Since the WhatsApp chat log is text-only, any image or video media is represented as a message with the text *'image omitted'* or *'video omitted'* in it. In addition, shared links are sent as an individual message with the *'https://'* prefix and categorized into a single token by `TweetTokenizer`. We can use this information to categorize message types, as well as emptying the respective '*text_processed*' field for images and videos (since they aren't 'real' text messages).<br>\n",
    "**Note:** The 'image omitted' and 'text omitted' text has a non-printable unicode typesetting character ([\\u200e](https://www.fileformat.info/info/unicode/char/200e/index.htm)), hence the reason it is tokenized into 3 tokens, rather than the expected 2. Hidden / nonstandard characters such as this will be cleaned out in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u200e'"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_raw'].iloc[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for categorizing messages into types (Warning, this function isn't very pythonic...)\n",
    "def categorize_message(tokenlist):\n",
    "    \"\"\"\n",
    "    Input:  Tokenized text string - i.e. list of words\n",
    "    Output: Tuple of the following: (String indicating type of message - 'image', 'video', 'link' or 'text'),\n",
    "                                     appropriate output token for the message type)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Identify links based on prefix\n",
    "    if (len(tokenlist) == 1):\n",
    "        if (tokenlist[0][:8] == 'https://'):\n",
    "            return ('link', tokenlist)\n",
    "    \n",
    "    # Identify images / video by default WhatsApp message (\"\\u200e image omitted\" or \"\\u200e video omitted\")\n",
    "    elif len(tokenlist) == 3:\n",
    "        if (tokenlist[2] == 'omitted'):\n",
    "            \n",
    "            if (tokenlist[1] == 'image'):\n",
    "                return ('image', [])\n",
    "            \n",
    "            elif (tokenlist[1] == 'video'):\n",
    "                return ('video', [])\n",
    "    \n",
    "    # Default is text\n",
    "    return ('text', tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[From, outside, came, the, occasional, cry, of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[and, lool, lool, lool, lool, once, at, our, v...</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[\\, which, told, us, that, the, cheetah, was, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hah, lmaoooo, wooowww]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[Far, away, we, could, hear, the, deep, tones,...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \n",
       "0  [From, outside, came, the, occasional, cry, of...         []     text  \n",
       "1  [and, lool, lool, lool, lool, once, at, our, v...  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text  \n",
       "2  [\\, which, told, us, that, the, cheetah, was, ...         []     text  \n",
       "3                            [hah, lmaoooo, wooowww]         []     text  \n",
       "4  [Far, away, we, could, hear, the, deep, tones,...     [ðŸ˜¯, â˜º]     text  "
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe\n",
    "messages['msg_type'], messages['text_processed'] = zip(*messages['text_processed'].apply(categorize_message))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video â€Žvideo omitted\n"
     ]
    }
   ],
   "source": [
    "print(messages['msg_type'].iloc[10], messages['text_raw'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** <br>\n",
    "Let's clean up the text by lowercasing all text, stripping leading / trailing whitespace, removing 'non-printable' characters (such punctuation and hidden characters such as '\\u200e' which may be embedded in our text messages). <br>\n",
    "**Note:** this may have the side effect of removing non-ascii characters, therefore might cause unintended behaviour if the message corpus contains **non-Latin (\"English\")** characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for cleaning up text (lowercasing all text + stripping whitespace + removing non-alphanumeric characters)\n",
    "def clean_text(tokenlist):\n",
    "    tokenlist_clean = []\n",
    "    \n",
    "    for token_raw in tokenlist:\n",
    "        token = token_raw.strip().lower()\n",
    "        token_clean = \"\".join(c for c in token if str.isalnum(c))\n",
    "        \n",
    "        if len(token_clean) > 0:\n",
    "            tokenlist_clean.append(token)\n",
    "            \n",
    "    return tokenlist_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[at, the, moment, when, holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [at, the, moment, when, holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [i, could, however, see, that, his, face, was,...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe, skipping any 'link' messages to preserve the html formatting, but cleaning the other message types\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(clean_text),\n",
    "                                      messages['text_processed'])\n",
    "\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7']\n"
     ]
    }
   ],
   "source": [
    "print(messages['text_processed'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** <br>\n",
    "Next, let's normalize our corpus to manage any slang and slang variants. The initial implementation attempted to use the `normalize` library found [here](https://github.com/EFord36/normalise), but processing runtime was infeasible for this dataset. As an alternative, I defined my own 'custom' normalizer to handle a user's 'chat-specific' slang. The normalizer primarily corrects slang words with repeated characters, as outlined in the comments below. The user can also define their own slang dictionary mappings in the auxiliary `Chat-History-User-Defined.ipynb` notebook. <br><br>\n",
    "**Note**: `TweetTokenizer` has a `reduce_len` parameter which accomplishes a similar functionality ([see here](https://www.nltk.org/api/nltk.tokenize.html) for details), but it treats words under the '3 repeated characters' limit as unique words, and is not user-customizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'Custom' normalizer:\n",
    "\n",
    "# 1) Define sets of 'slang' strings based on type of expected non-normalization, for example:\n",
    "# --- end-letter repeats (omgggg -> omg)\n",
    "# --- combination repeats (wooowww -> wow)\n",
    "# --- mid-letter repeats (looool -> lol)         [implemented via separate 'custom' dict instead]\n",
    "# --- two-letter repeats (hahahaha -> haha)      [implemented via separate 'custom' dict instead]\n",
    "# 2) Generate dicts which map slang variant to its 'root' form.\n",
    "# --- Will be specific for each set and have an 'upper bound' number of repeats\n",
    "# 3) Combine to a master 'normalization' dict. Define the custom normalization function to parse through the dict and evaluate feasibility of scaling up\n",
    "\n",
    "# Expected runtime O(n*m) where n = number of tokens in corpus, m = number of keys in master normalization lookup dict\n",
    "# Will be slow, but potentially m will at least 1-2 orders of magnitude smaller than using `normalise` library\n",
    "\n",
    "# Custom / User defined:\n",
    "# --- 'base' slang words and their 'type'\n",
    "# --- 'upper bound' on number of repeats for dict generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to generate dicts of slang strings based on their type\n",
    "def generate_slang_variants(SLANG_DICT, LIMIT = 5):\n",
    "    \"\"\"\n",
    "    Input:    LIMIT:            Integer defining maximum number of repeated letters.\n",
    "                                Default is 5 (i.e, 5 repeated single / double letters in the variant)\n",
    "              SLANG_DICT:       Dictionary of string: integer pairs.\n",
    "                                Strings are slang 'base' words. Integers are the slang variant 'type'defined below:\n",
    "                                1 == Repeating single final letter (eg. lmaooooo -> lmao)\n",
    "                                2 == Repeating double final letters (eg. wooooowwwww -> wow)\n",
    "                                \n",
    "    Output:   slang_lookup:     Dictionary of slang-variant : slang-root pairs\n",
    "    \"\"\"\n",
    "    slang_lookup = {}\n",
    "    \n",
    "    for root in SLANG_DICT: #root[-2:]\n",
    "                \n",
    "        if SLANG_DICT[root] == 1:\n",
    "            # Case 1: Repeat the single final letter up to limit. Add to final dictionary with root as value\n",
    "            for i in range(LIMIT):\n",
    "                variant = root + (root[-1]*i)\n",
    "                slang_lookup.update({variant : root})\n",
    "            \n",
    "        elif SLANG_DICT[root] == 2:\n",
    "            # Case 2: Generate combinations of both final letters up to limit. Add to final dictionary with root as value\n",
    "            for i in range(1, LIMIT+1):\n",
    "                for j in range(1, LIMIT+1):\n",
    "                    variant = root[:-2] + (root[-2]*i) + (root[-1]*j)\n",
    "                    slang_lookup.update({variant : root})\n",
    "    \n",
    "    return slang_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary function to normalize slang variants to their 'base' slang form\n",
    "def normalize_slang(tokenlist, slang_lookup):\n",
    "    \"\"\"\n",
    "    Input:    tokenlist:               Tokenized corpus to be parsed and normalized\n",
    "              slang_lookup:            Dictionary of slang-variant : slang-root pairs\n",
    "\n",
    "    Output:   tokenlist_normalized:    Normalized, tokenized corpus\n",
    "    \"\"\"\n",
    "    tokenlist_normalized = []\n",
    "    \n",
    "    for token in tokenlist:\n",
    "        if token in slang_lookup:\n",
    "            tokenlist_normalized.append(slang_lookup[token])\n",
    "        else:\n",
    "            tokenlist_normalized.append(token)\n",
    "    \n",
    "    return tokenlist_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final dictionary mapping slang variants to their 'base' slang word.\n",
    "slang_lookup = generate_slang_variants(SLANG_DICT, VARIANT_LIMIT)\n",
    "\n",
    "# 'Custom' slang variants are added to this final dictionary as well\n",
    "slang_lookup.update(SLANG_SPECIAL_CASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[at, the, moment, when, holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [at, the, moment, when, holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [i, could, however, see, that, his, face, was,...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe and normalize slang on non-link messages\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(lambda x: normalize_slang(x, slang_lookup)),\n",
    "                                      messages['text_processed'])\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:**<br>\n",
    "Finally, let's remove common [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) from our tokenized and cleaned (non-link) messages. This will ensure our data isn't polluted by common-use words. The user can also define additional stopwords in the `Chat-History-User-Defined.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard set of stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Add user-defined custom stopwords to set\n",
    "stopwords_set = stopwords_set | STOPWORDS_EXTRA\n",
    "\n",
    "# List comprehension helper function to remove stopwords\n",
    "def remove_stopwords(tokenlist):\n",
    "    return [word.lower() for word in tokenlist if word.lower() not in stopwords_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[outside, came, occasional, cry, night-bird]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[window, long, drawn, catlike, whine]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[told, us, cheetah, indeed, liberty]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hahaha, lmao, wow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \n",
       "0       [outside, came, occasional, cry, night-bird]         []     text  \n",
       "1              [window, long, drawn, catlike, whine]  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text  \n",
       "2               [told, us, cheetah, indeed, liberty]         []     text  \n",
       "3                                [hahaha, lmao, wow]         []     text  \n",
       "4  [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text  "
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe and remove stopwords on non-link messages\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(remove_stopwords),\n",
    "                                      messages['text_processed'])\n",
    "#messages['text_processed'] = messages['text_processed'].apply(remove_stopwords)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[moment, holmes, struck, light, heard, low, cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[sudden, glare, flashing, weary, eyes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, impossible, tell, friend, lashed, savag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [moment, holmes, struck, light, heard, low, cl...         []     text  \n",
       "30             [sudden, glare, flashing, weary, eyes]         []     text  \n",
       "31  [made, impossible, tell, friend, lashed, savag...         []     text  \n",
       "32  [could, however, see, face, deadly, pale, fill...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7']\n"
     ]
    }
   ],
   "source": [
    "print(messages['text_processed'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've reduced our text messages to their keywords, lets add a column counting the number of keywords per message (which can be a basic, analagous metric for message length or complexity). We can add a similar column for number of emojis. We can also add a column for number of characters in the raw text message. **Note:** This will include all the 'cleaned' characters such as punctuation and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>count_keywords</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>count_raw_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[outside, came, occasional, cry, night-bird]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[window, long, drawn, catlike, whine]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[told, us, cheetah, indeed, liberty]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hahaha, lmao, wow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \\\n",
       "0       [outside, came, occasional, cry, night-bird]         []     text   \n",
       "1              [window, long, drawn, catlike, whine]  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text   \n",
       "2               [told, us, cheetah, indeed, liberty]         []     text   \n",
       "3                                [hahaha, lmao, wow]         []     text   \n",
       "4  [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text   \n",
       "\n",
       "   count_keywords  count_emojis  count_raw_chars  \n",
       "0               5             0               52  \n",
       "1               5             3               78  \n",
       "2               5             0               55  \n",
       "3               3             0               19  \n",
       "4               8             2               61  "
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['count_keywords'] = messages['text_processed'].apply(len)\n",
    "messages['count_emojis'] = messages['emojis'].apply(len)\n",
    "messages['count_raw_chars'] = messages['text_raw'].apply(len)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part! Let's make a list of potential data vizualizations, in the context of a two-person WhatsApp conversation:\n",
    "1. General stats, including:\n",
    "    - Image / Video / Link / Text message totals per person\n",
    "    - Average number of words per message\n",
    "    - Average number of characters per message\n",
    "    - Average number of emojis per message\n",
    "    - Top 5 days with most messages sent\n",
    "    - Top 5 longest messages\n",
    "    - Top 5 messages with the most emojis\n",
    "2. Daily (or weekly if too noisy) time series for number of messages. Can annotate based on known life events.\n",
    "3. Word-based statistics, including:\n",
    "    - Most used words, broken down by person. Can annotate or draw attention to 'interesting' or 'key' words.\n",
    "    - Longest word used by each person.\n",
    "4. Most used emojis, broken down by person.\n",
    "5. Average message qty by day of week - can also extend to identify which hours were the busiest\n",
    "6. Longest consecutive days without messages sent by either person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep track of which dataframes can be used for each vizualization - and create new ones if needed (TBD if not yet investigated or implemented)!\n",
    "1. `msg_summary_type`, `msg_summary_counts`, `messages` and `timeseries`\n",
    "2. `timeseries`\n",
    "3. `text_expanded_by_user`\n",
    "4. `emoji_expanded_by_user`\n",
    "5. `timeseries_weekday_hour`\n",
    "6. `timeseries_deltas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 1:**\n",
    "- Total messages sent by user and category can be easily pivoted out from the `messages` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "msg_type  image  link  text  video\n",
       "username                          \n",
       "User 1      1.0   0.0  18.0    1.0\n",
       "User 2      0.0   1.0  13.0    0.0"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_summary_type = pd.pivot_table(messages,\n",
    "                                  values='text_processed',\n",
    "                                  index='username',\n",
    "                                  columns='msg_type',\n",
    "                                  aggfunc=len).fillna(0)\n",
    "msg_summary_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Average number of keywords per text message, average number of characters per text message, and average number of emojis per message can be pivoted out from `messages`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>count_keywords</th>\n",
       "      <th>count_raw_chars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>4.611111</td>\n",
       "      <td>48.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>51.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count_emojis  count_keywords  count_raw_chars\n",
       "username                                               \n",
       "User 1        0.777778        4.611111        48.222222\n",
       "User 2        0.923077        4.846154        51.230769"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_summary_counts = pd.pivot_table(messages[messages['msg_type']=='text'],\n",
    "                                    values=['count_keywords', 'count_emojis', 'count_raw_chars'],\n",
    "                                    index='username',\n",
    "                                    aggfunc=np.mean).fillna(0)\n",
    "\n",
    "msg_summary_counts\n",
    "#msg_summary_counts[msg_summary_counts['msg_type']=='text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To find the top 5 days with most messages sent, we can pivot `messages` to create a dataframe with records [grouped by day](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) and broken down by user + type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:55:53-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:56:07-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:56:08-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:56:27-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29 17:56:40-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2     \n",
       "msg_type                   image text video   link text\n",
       "date_time                                              \n",
       "2020-02-28 02:55:53-05:00    0.0  1.0   0.0    0.0  1.0\n",
       "2020-02-28 02:56:07-05:00    0.0  0.0   0.0    0.0  1.0\n",
       "2020-02-28 02:56:08-05:00    0.0  0.0   0.0    0.0  1.0\n",
       "2020-02-28 02:56:27-05:00    0.0  1.0   0.0    0.0  0.0\n",
       "2020-02-29 17:56:40-05:00    0.0  0.0   0.0    0.0  1.0"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot\n",
    "timeseries_raw = pd.pivot_table(messages,\n",
    "                                values='text_processed',\n",
    "                                index='date_time', \n",
    "                                columns=['username', 'msg_type'], \n",
    "                                aggfunc=len).fillna(0)\n",
    "timeseries_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-01 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-08 00:00:00-05:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-07 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2      total\n",
       "msg_type                   image text video   link text      \n",
       "date_time                                                    \n",
       "2020-03-01 00:00:00-05:00    0.0  4.0   0.0    0.0  4.0   8.0\n",
       "2020-03-08 00:00:00-05:00    1.0  4.0   0.0    1.0  2.0   8.0\n",
       "2020-02-29 00:00:00-05:00    0.0  4.0   1.0    0.0  1.0   6.0\n",
       "2020-02-28 00:00:00-05:00    0.0  2.0   0.0    0.0  3.0   5.0\n",
       "2020-03-07 00:00:00-05:00    0.0  2.0   0.0    0.0  2.0   4.0"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample dataframe by day, create total column\n",
    "timeseries = timeseries_raw.resample('D').sum()\n",
    "timeseries['total'] = timeseries.sum(axis=1)\n",
    "\n",
    "# Sort from most to least messages and show top 5\n",
    "timeseries.sort_values(by='total', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can leverage the 'count_keywords' column in `messages` to identify what the longest 5 messages are, and their associated details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>count_keywords</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>count_raw_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>--a very gentle, soothing sound, like that of ...</td>\n",
       "      <td>2020-03-02 22:20:32-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[gentle, soothing, sound, like, small, jet, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[moment, holmes, struck, light, heard, low, cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29 18:00:23-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[still, sat, waiting, silently, whatever, migh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "21  --a very gentle, soothing sound, like that of ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "4   ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "9   and still we sat waiting silently for whatever...   \n",
       "\n",
       "                   date_time username  \\\n",
       "21 2020-03-02 22:20:32-05:00   User 2   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "4  2020-02-28 02:56:27-05:00   User 1   \n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "9  2020-02-29 18:00:23-05:00   User 1   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \\\n",
       "21  [gentle, soothing, sound, like, small, jet, st...         []     text   \n",
       "32  [could, however, see, face, deadly, pale, fill...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text   \n",
       "4   [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text   \n",
       "29  [moment, holmes, struck, light, heard, low, cl...         []     text   \n",
       "9   [still, sat, waiting, silently, whatever, migh...         []     text   \n",
       "\n",
       "    count_keywords  count_emojis  count_raw_chars  \n",
       "21              10             0              101  \n",
       "32               9             3               91  \n",
       "4                8             2               61  \n",
       "29               8             0               71  \n",
       "9                7             0               61  "
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.nlargest(5, 'count_keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This approach can be repeated to identify the 3 most emoji-heavy messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>count_keywords</th>\n",
       "      <th>count_emojis</th>\n",
       "      <th>count_raw_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[window, long, drawn, catlike, whine]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "1   and lool lool lool lool once at our very windo...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "4   ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                   date_time username  \\\n",
       "1  2020-02-28 02:55:53-05:00   User 2   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "4  2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \\\n",
       "1               [window, long, drawn, catlike, whine]  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text   \n",
       "32  [could, however, see, face, deadly, pale, fill...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text   \n",
       "4   [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text   \n",
       "\n",
       "    count_keywords  count_emojis  count_raw_chars  \n",
       "1                5             3               78  \n",
       "32               9             3               91  \n",
       "4                8             2               61  "
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.nlargest(3, 'count_emojis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed into out data visualizations, we need to unstack the dataframe as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msg_type</th>\n",
       "      <th>username</th>\n",
       "      <th>msg_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image</td>\n",
       "      <td>User 1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image</td>\n",
       "      <td>User 2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>link</td>\n",
       "      <td>User 1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>link</td>\n",
       "      <td>User 2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "      <td>User 1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text</td>\n",
       "      <td>User 2</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>video</td>\n",
       "      <td>User 1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video</td>\n",
       "      <td>User 2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  msg_type username  msg_qty\n",
       "0    image   User 1      1.0\n",
       "1    image   User 2      0.0\n",
       "2     link   User 1      0.0\n",
       "3     link   User 2      1.0\n",
       "4     text   User 1     18.0\n",
       "5     text   User 2     13.0\n",
       "6    video   User 1      1.0\n",
       "7    video   User 2      0.0"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz_messages_summary = msg_summary_type.unstack().rename('msg_qty').reset_index()\n",
    "viz_messages_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which will let us plot the data using `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2728e5b5d48>"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=viz_messages_summary[viz_messages_summary[\"msg_type\"]!=\"text\"], x=\"msg_type\", y=\"msg_qty\", hue=\"username\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 2:**<br>\n",
    "The `timeseries` dataframe can be used to create a 'run chart' of day-by-day message counts, separated by user. Given the expected noisiness of the data if done over a long time frame, the vizualization is meant as a primarily birds-eye view of the data (as well as being able to highlight noteable areas of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>date_time</th>\n",
       "      <th>msg_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>image</td>\n",
       "      <td>2020-02-28 00:00:00-05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 1</td>\n",
       "      <td>image</td>\n",
       "      <td>2020-02-29 00:00:00-05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User 1</td>\n",
       "      <td>image</td>\n",
       "      <td>2020-03-01 00:00:00-05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User 1</td>\n",
       "      <td>image</td>\n",
       "      <td>2020-03-02 00:00:00-05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>image</td>\n",
       "      <td>2020-03-03 00:00:00-05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username msg_type                 date_time  msg_qty\n",
       "0   User 1    image 2020-02-28 00:00:00-05:00      0.0\n",
       "1   User 1    image 2020-02-29 00:00:00-05:00      0.0\n",
       "2   User 1    image 2020-03-01 00:00:00-05:00      0.0\n",
       "3   User 1    image 2020-03-02 00:00:00-05:00      0.0\n",
       "4   User 1    image 2020-03-03 00:00:00-05:00      0.0"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unstack and reindex timeseries dataframe to make a plot-friendly version\n",
    "viz_timeseries = timeseries.drop(columns=\"total\").unstack().rename(\"msg_qty\").reset_index()\n",
    "viz_timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the limits for the plot's x-axis\n",
    "time_start = viz_timeseries.iloc[0]['date_time'].replace(day=1) - dt.timedelta(days=1)                             # Last day of previous month\n",
    "time_end = viz_timeseries.iloc[-1]['date_time'].replace(day=1, month=viz_timeseries.iloc[-1]['date_time'].month+1) # First day of next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to define tick positions and tick labels for the additional 'year' axis included in the plot\n",
    "def find_xaxis_params(axis, time_start, time_end):\n",
    "    \"\"\"\n",
    "    Input:    axis:             Matplotlib axis object - the 'original' x-axis of the plot with ticks defined outside the function \n",
    "    \n",
    "              time_start:       Starting datetime object of the x-axis plot. Defined as:\n",
    "                                    - First chronological datetime from the viz_timeseries dataframe\n",
    "                                    - Day set to 1st of that month\n",
    "                                    - Moved back 1 day (i.e, last day of the previous month)\n",
    "                                    \n",
    "              time_end:         Ending datetime object of the x-axis plot. Defined as:\n",
    "                                    - Last chronological datetime from the viz_timeseries dataframe\n",
    "                                    - Day set to 1st of that month\n",
    "                                    - Moved forward 1 month (i.e, first day of the next month)\n",
    "    \n",
    "    Output:   Tuple of the following:\n",
    "              year_ticks:       List of relative positions (0 - 1) corresponding to each tick where a year begins\n",
    "              year_labels:      List of strings with the name of the year\n",
    "              year_label_ticks: List of relative positions (0 - 1) corresponding to the tick where the year label is drawn\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the relative positions (from 0 - 1) of each tick in the x-axis\n",
    "    x_min, x_max = axis.get_xlim()\n",
    "    ticks = [(tick - x_min)/(x_max - x_min) for tick in axis.get_xticks()]\n",
    "    \n",
    "    # Get datetime which matches the first displayed label on the x-axis\n",
    "    time_start_label = time_start + dt.timedelta(days=1)\n",
    "    \n",
    "    # Get datetime which matches the last displayed label on the x-axis\n",
    "    time_end_label = time_end\n",
    "    \n",
    "    \n",
    "    # Define initial values for our outputs and helper variable 'year_ticks_index'\n",
    "    year_ticks = [ticks[0]]\n",
    "    year_ticks_index = [0]\n",
    "    year_labels = [time_start_label.strftime(\"%Y\")]\n",
    "    year_label_ticks = []\n",
    "    prev_label = time_start_label\n",
    "    \n",
    "    # Loop through each tick (skipping first)\n",
    "    for idx, tick in enumerate(ticks[1:], start=1):\n",
    "        curr_label = prev_label + relativedelta(months=1)\n",
    "\n",
    "        # If the year has changed, store the value and index of that particular tick. Also capture the year name\n",
    "        if (curr_label.year != prev_label.year):\n",
    "            year_ticks.append(tick)\n",
    "            year_ticks_index.append(idx)\n",
    "            year_labels.append(curr_label.strftime(\"%Y\"))\n",
    "\n",
    "        prev_label = curr_label\n",
    "\n",
    "        \n",
    "    # Add the value and index of the last tick to their respective lists\n",
    "    year_ticks.append(ticks[-1])\n",
    "    year_ticks_index.append(len(ticks)-1)\n",
    "    \n",
    "    \n",
    "    # Loop through each year-tick (ending before the last element since we are forward-windowing in this loop)\n",
    "    for idx, tick in enumerate(year_ticks_index[:-1]):\n",
    "\n",
    "        # Calculate the delta between the current year-tick and next year-tick\n",
    "        delta = year_ticks_index[idx+1] - year_ticks_index[idx]\n",
    "        i = year_ticks_index[idx] + int(delta // 2)\n",
    "        j = i + 1\n",
    "        \n",
    "        # If delta is even, use middle tick between the year-ticks. Else average between the middle ticks.\n",
    "        if (delta % 2 == 0):\n",
    "            year_label_ticks.append(ticks[i])\n",
    "        else:\n",
    "            year_label_ticks.append((ticks[i]+ticks[j]) / 2)\n",
    "\n",
    "    return (year_ticks, year_labels, year_label_ticks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from mpl_toolkits to handle duplicate ('parasite') axes on the original ('host') plot\n",
    "from mpl_toolkits.axes_grid.parasite_axes import SubplotHost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define plot size, initial axes, and plot using Seaborn\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax1 = SubplotHost(fig, 111)\n",
    "fig.add_subplot(ax1)\n",
    "ax1 = sns.lineplot(data=viz_timeseries, x=\"date_time\", y=\"msg_qty\", hue=\"username\", ci=None, estimator='sum')\n",
    "\n",
    "# Define by-month ticks on x-axis, define formatting, and define limits\n",
    "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter(\"%d-%b\"))\n",
    "ax1.set_xlim(left=time_start, right=time_end)\n",
    "\n",
    "# Use helper function to define tick parameters for the second 'parasite' axis\n",
    "year_ticks, year_labels, year_label_ticks = find_xaxis_params(ax1, time_start, time_end)\n",
    "\n",
    "# Create second axis, position, and modify visibility\n",
    "ax2 = ax1.twiny()\n",
    "offset = 0, -35    # Hardcoded position of the second axis\n",
    "new_axisline = ax2.get_grid_helper().new_fixed_axis\n",
    "ax2.axis[\"bottom\"] = new_axisline(loc=\"bottom\", axes=ax2, offset=offset)\n",
    "ax2.axis[\"top\"].set_visible(False)\n",
    "ax1.axis[\"top\"].set_visible(True)\n",
    "\n",
    "# Define / draw second axis using params\n",
    "ax2.set_xticks(year_ticks)\n",
    "ax2.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax2.xaxis.set_minor_locator(ticker.FixedLocator(year_label_ticks))\n",
    "ax2.xaxis.set_minor_formatter(ticker.FixedFormatter(year_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 3:**<br>\n",
    "- Creating 'by user' visualizations require us to have access to the individual tokens in `messages[text_processed]`. We can explode out each token to a new row and preserve usernames (in a new dataframe) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>occasional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>night-bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username text_processed\n",
       "0   User 1        outside\n",
       "0   User 1           came\n",
       "0   User 1     occasional\n",
       "0   User 1            cry\n",
       "0   User 1     night-bird"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_expanded = messages[['username','text_processed']].explode('text_processed').dropna()\n",
    "text_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pivot this data such that we obtain rows for counts of each unique word, broken down per user. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lmao</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hahaha</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>see</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sound</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>struck</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gentle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>could</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hour</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_processed  User 1  User 2  total\n",
       "0           lmao     4.0     1.0    5.0\n",
       "1         hahaha     3.0     1.0    4.0\n",
       "2            see     2.0     1.0    3.0\n",
       "3          sound     2.0     1.0    3.0\n",
       "4         struck     2.0     1.0    3.0\n",
       "5          heard     1.0     2.0    3.0\n",
       "6         gentle     1.0     1.0    2.0\n",
       "7          smell     1.0     1.0    2.0\n",
       "8          could     1.0     1.0    2.0\n",
       "9           hour     1.0     1.0    2.0"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot\n",
    "text_expanded_by_user = text_expanded.pivot_table(text_expanded, \n",
    "                                                  index='text_processed', \n",
    "                                                  columns='username', \n",
    "                                                  aggfunc=len).fillna(0)\n",
    "\n",
    "# Create and populate a 'total' column\n",
    "text_expanded_by_user['total'] = text_expanded_by_user.sum(axis=1)\n",
    "\n",
    "# Sort by most common words\n",
    "text_expanded_by_user.sort_values(by='total', ascending=False, inplace=True)\n",
    "        \n",
    "# Re-index dataframe and fix column naming\n",
    "text_expanded_by_user = text_expanded_by_user.reset_index()\n",
    "text_expanded_by_user.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "text_expanded_by_user.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding the longest used word requires a bit of additional manipulation of the `text_expanded_by_user` dataset. The wordlist includes url text so we need to lookup each word in an English language dictionary (`words` from `nltk.corpus` in this case - it isn't the best wordlist but it probably isn't worth the effort to import a large library for the sake of a one-line visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "wordset = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_processed    immediately\n",
       "User 1                      0\n",
       "User 2                      1\n",
       "total                       1\n",
       "word_len                   11\n",
       "english_word             True\n",
       "Name: 108, dtype: object"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column to capture word lengths (will be used later)\n",
    "text_expanded_by_user['word_len'] = text_expanded_by_user['text_processed'].apply(len)\n",
    "\n",
    "# Sort text_expanded_by_user based on word length\n",
    "#wordlist = pd.DataFrame(text_expanded_by_user.sort_values(by='word_len', ascending=False))\n",
    "\n",
    "# Add a column to determine word presence in English\n",
    "text_expanded_by_user[\"english_word\"] = text_expanded_by_user[\"text_processed\"].apply(lambda x: x in wordset)\n",
    "\n",
    "# Sort by word length and English-only words, and select longest word\n",
    "text_expanded_by_user[text_expanded_by_user['english_word']].sort_values(by='word_len', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 4:**<br>\n",
    "We can repeat the process above to obtain a similar dataframe for emojis. **Note:** Need to'de-emojize' before pivoting, since many identical emojis were unnecessarily represented differently in unicode. To display as emojis in visualizations, must 're-emojize' the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>â˜º</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username emojis\n",
       "1   User 2      ðŸ˜¯\n",
       "1   User 2      ðŸ˜¯\n",
       "1   User 2      ðŸ˜¯\n",
       "4   User 1      ðŸ˜¯\n",
       "4   User 1      â˜º"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_expanded = messages[['username','emojis']].explode('emojis').dropna()\n",
    "emoji_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emojis</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>total</th>\n",
       "      <th>emojis_disp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:hushed_face:</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:loudly_crying_face:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ðŸ˜­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:eyes:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ðŸ‘€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:grinning_squinting_face:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ðŸ˜†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:smiling_face:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>â˜º</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>:frowning_face:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>â˜¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>:grinning_face_with_smiling_eyes:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ðŸ˜„</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              emojis  User 1  User 2  total emojis_disp\n",
       "0                      :hushed_face:     7.0     4.0   11.0           ðŸ˜¯\n",
       "1               :loudly_crying_face:     0.0     7.0    7.0           ðŸ˜­\n",
       "2                             :eyes:     2.0     0.0    2.0           ðŸ‘€\n",
       "3          :grinning_squinting_face:     2.0     0.0    2.0           ðŸ˜†\n",
       "4                     :smiling_face:     2.0     0.0    2.0           â˜º\n",
       "5                    :frowning_face:     1.0     0.0    1.0           â˜¹\n",
       "6  :grinning_face_with_smiling_eyes:     0.0     1.0    1.0           ðŸ˜„"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De-emoji in-progress dataframe\n",
    "emoji_expanded['emojis'] = emoji_expanded['emojis'].apply(emoji.demojize)\n",
    "\n",
    "# Pivot\n",
    "emoji_expanded_by_user = emoji_expanded.pivot_table(emoji_expanded, \n",
    "                                                  index='emojis', \n",
    "                                                  columns='username', \n",
    "                                                  aggfunc=len).fillna(0)\n",
    "\n",
    "# Create and populate a 'total' column\n",
    "emoji_expanded_by_user['total'] = emoji_expanded_by_user.sum(axis=1)\n",
    "\n",
    "# Sort by most common emojis\n",
    "emoji_expanded_by_user.sort_values(by='total', ascending=False, inplace=True)\n",
    "\n",
    "# Re-index dataframe and fix column naming\n",
    "emoji_expanded_by_user = emoji_expanded_by_user.reset_index()\n",
    "emoji_expanded_by_user.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "# 'Re-emoji' in a separate column\n",
    "emoji_expanded_by_user['emojis_disp'] = emoji_expanded_by_user['emojis'].apply(emoji.emojize)\n",
    "\n",
    "emoji_expanded_by_user.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ˜¯'"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_expanded_by_user['emojis_disp'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 5:**<br>\n",
    "To get a day-of-the-week breakdown of messaging data, we'll need to adopt a similar resampling approach as the `timeseries` dataframe, but with a bit more creativity to give the hour-by-hour granularity desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 03:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 04:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 05:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 06:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2     \n",
       "msg_type                   image text video   link text\n",
       "date_time                                              \n",
       "2020-02-28 02:00:00-05:00    0.0  2.0   0.0    0.0  3.0\n",
       "2020-02-28 03:00:00-05:00    0.0  0.0   0.0    0.0  0.0\n",
       "2020-02-28 04:00:00-05:00    0.0  0.0   0.0    0.0  0.0\n",
       "2020-02-28 05:00:00-05:00    0.0  0.0   0.0    0.0  0.0\n",
       "2020-02-28 06:00:00-05:00    0.0  0.0   0.0    0.0  0.0"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the timeseries_raw dataframe used earlier by hour.\n",
    "timeseries_weekday_hour = timeseries_raw.resample('H').sum()\n",
    "#timeseries_weekday['total'] = timeseries_weekday.sum(axis=1)\n",
    "#timeseries.sort_values(by='total', ascending=False, inplace=True)\n",
    "timeseries_weekday_hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reindex the dataframe to a 'weekday-hour' multindex format. Let's start by generating these columns from the datetime object found in the index, using a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract weekday (text) and hour (int) from a datetime object.\n",
    "def extract_weekday_hour(datetime_obj):\n",
    "    \"\"\"\n",
    "    Input:  Python Datetime object            \n",
    "    Output: Tuple: (String with weekday of datetime object, Int with hour of datetime object (24h))\n",
    "    \"\"\"\n",
    "    return (datetime_obj.strftime('%A'), datetime_obj.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 03:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 04:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 05:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 06:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 07:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 08:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 09:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 10:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 11:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 12:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 13:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 14:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 15:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 16:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 17:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 18:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 19:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 21:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 22:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 23:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29 01:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2        weekday hour\n",
       "msg_type                   image text video   link text               \n",
       "date_time                                                             \n",
       "2020-02-28 02:00:00-05:00    0.0  2.0   0.0    0.0  3.0    Friday    2\n",
       "2020-02-28 03:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    3\n",
       "2020-02-28 04:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    4\n",
       "2020-02-28 05:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    5\n",
       "2020-02-28 06:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    6\n",
       "2020-02-28 07:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    7\n",
       "2020-02-28 08:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    8\n",
       "2020-02-28 09:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday    9\n",
       "2020-02-28 10:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   10\n",
       "2020-02-28 11:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   11\n",
       "2020-02-28 12:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   12\n",
       "2020-02-28 13:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   13\n",
       "2020-02-28 14:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   14\n",
       "2020-02-28 15:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   15\n",
       "2020-02-28 16:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   16\n",
       "2020-02-28 17:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   17\n",
       "2020-02-28 18:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   18\n",
       "2020-02-28 19:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   19\n",
       "2020-02-28 20:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   20\n",
       "2020-02-28 21:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   21\n",
       "2020-02-28 22:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   22\n",
       "2020-02-28 23:00:00-05:00    0.0  0.0   0.0    0.0  0.0    Friday   23\n",
       "2020-02-29 00:00:00-05:00    0.0  0.0   0.0    0.0  0.0  Saturday    0\n",
       "2020-02-29 01:00:00-05:00    0.0  0.0   0.0    0.0  0.0  Saturday    1"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to the dataframe:\n",
    "timeseries_weekday_hour['weekday'], timeseries_weekday_hour['hour'] = zip(*timeseries_weekday_hour.index.map(extract_weekday_hour))\n",
    "timeseries_weekday_hour.head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to reindex the dataframe, and then aggregate it (using mean and unstack+stack). We can also create a total column as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">Friday</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username     User 1            User 2      total\n",
       "msg_type      image text video   link text      \n",
       "weekday hour                                    \n",
       "Friday  0       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        1       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        2       0.0  1.0   0.0    0.0  1.5   2.5\n",
       "        3       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        4       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        5       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        6       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        7       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        8       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        9       0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        10      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        11      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        12      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        13      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        14      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        15      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        16      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        17      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        18      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        19      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        20      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        21      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        22      0.0  0.0   0.0    0.0  0.0   0.0\n",
       "        23      0.0  0.0   0.0    0.0  0.0   0.0"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reindex\n",
    "timeseries_weekday_hour.set_index(['weekday', 'hour'], inplace=True)\n",
    "\n",
    "# Aggregate\n",
    "timeseries_weekday_hour = timeseries_weekday_hour.mean(level=[0,1]).unstack().stack(dropna=False)\n",
    "\n",
    "# Add total column\n",
    "timeseries_weekday_hour['total'] = timeseries_weekday_hour.sum(axis=1)\n",
    "\n",
    "timeseries_weekday_hour.head(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 6:**<br>\n",
    "To find the longest consecutive gap (in days/hours) between messages, we can leverage Pandas' built-in [df.diff()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.diff.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>00:00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>00:00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date_time msg_type   deltas\n",
       "0 2020-02-28 02:55:53-05:00     text      NaT\n",
       "1 2020-02-28 02:55:53-05:00     text 00:00:00\n",
       "2 2020-02-28 02:56:07-05:00     text 00:00:14\n",
       "3 2020-02-28 02:56:08-05:00     text 00:00:01\n",
       "4 2020-02-28 02:56:27-05:00     text 00:00:19"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract non-aggregated datetime and message type fields directly from 'messages' dataframe\n",
    "timeseries_deltas = pd.DataFrame(messages[['date_time', 'msg_type']])\n",
    "\n",
    "# Calculate time deltas\n",
    "timeseries_deltas['deltas'] = timeseries_deltas['date_time'].diff()\n",
    "\n",
    "timeseries_deltas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-03-07 00:45:42-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>4 days 02:25:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-03-02 22:10:29-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>1 days 17:00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-03-08 17:10:08-04:00</td>\n",
       "      <td>text</td>\n",
       "      <td>1 days 16:00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-29 17:56:40-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>1 days 15:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-01 03:02:42-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>0 days 08:47:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_time msg_type          deltas\n",
       "22 2020-03-07 00:45:42-05:00     text 4 days 02:25:10\n",
       "19 2020-03-02 22:10:29-05:00     text 1 days 17:00:21\n",
       "26 2020-03-08 17:10:08-04:00     text 1 days 16:00:12\n",
       "5  2020-02-29 17:56:40-05:00     text 1 days 15:00:13\n",
       "11 2020-03-01 03:02:42-05:00     text 0 days 08:47:30"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find top 5 largest gaps between messages (any message type)\n",
    "timeseries_deltas.nlargest(5, 'deltas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-03-07 00:45:42-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>4 days 02:25:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-03-02 22:10:29-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>1 days 17:00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-03-08 17:10:08-04:00</td>\n",
       "      <td>text</td>\n",
       "      <td>1 days 16:00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-29 17:56:40-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>1 days 15:00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-03-01 03:02:42-05:00</td>\n",
       "      <td>text</td>\n",
       "      <td>0 days 08:47:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_time msg_type          deltas\n",
       "22 2020-03-07 00:45:42-05:00     text 4 days 02:25:10\n",
       "19 2020-03-02 22:10:29-05:00     text 1 days 17:00:21\n",
       "26 2020-03-08 17:10:08-04:00     text 1 days 16:00:12\n",
       "5  2020-02-29 17:56:40-05:00     text 1 days 15:00:13\n",
       "11 2020-03-01 03:02:42-05:00     text 0 days 08:47:30"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find top 5 largest gaps between messages (text messages)\n",
    "timeseries_deltas[timeseries_deltas['msg_type']=='text'].nlargest(5, 'deltas')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasciproj]",
   "language": "python",
   "name": "conda-env-datasciproj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
