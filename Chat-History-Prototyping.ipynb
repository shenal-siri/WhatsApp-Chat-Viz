{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Chat History Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Disclaimer: This is a work-in-progress notebook for prototyping my chat log data visualization tool. Code here has been minimally refactored / vectorized / optimized and therefore has plenty of scope for improvement!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by importing our bread-and-butter data and visualization libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the custom dictionaries defined in `Chat-History-Custom-Functs.ipynb` (which will be used in the text normalization process). Feel free to edit the dictionaries based on the desired normalization in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Chat-History-User-Defined.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the WhatsApp chat log (exported from an iOS device) to a dataframe and make a deepcopy for us to try out all of our preprocessing on. <br>\n",
    "**Note:** For privacy purposes, the chat log available on GitHub is much shorter and consists of dummy text, albeit maintaining WhatsApp's export style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 1: From outside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 2: and lool lool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2020-02-28, 2:56:07 AM] User 2: \\ which told ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2020-02-28, 2:56:27 AM] User 1: ðŸ˜¯ Far away we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw\n",
       "0  [2020-02-28, 2:55:53 AM] User 1: From outside ...\n",
       "1  [2020-02-28, 2:55:53 AM] User 2: and lool lool...\n",
       "2  [2020-02-28, 2:56:07 AM] User 2: \\ which told ...\n",
       "3  [2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...\n",
       "4  [2020-02-28, 2:56:27 AM] User 1: ðŸ˜¯ Far away we..."
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Whatsapp chat log to a dataframe\n",
    "\n",
    "imported_messages = pd.read_csv('chat.txt', delimiter='\\n', skiprows=[0], names = ['text_raw'])\n",
    "imported_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[2020-03-08, 05:20:32 PM] User 2: At the momen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[2020-03-08, 05:45:56 PM] User 1: lool but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[2020-03-08, 05:50:34 PM] User 2: I could, how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[2020-03-08, 05:52:12 PM] User 2: https://towa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "29  [2020-03-08, 05:20:32 PM] User 2: At the momen...\n",
       "30  [2020-03-08, 05:45:56 PM] User 1: lool but the...\n",
       "31  made it impossible for me to tell what it was ...\n",
       "32  [2020-03-08, 05:50:34 PM] User 2: I could, how...\n",
       "33  [2020-03-08, 05:52:12 PM] User 2: https://towa..."
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Using '\\n' as the delimiter results in messages with embedded line breaks escaping to new rows in the dataframe. These rows will not have the '*\\[datetime\\] username: text*' pattern seen in other rows, so we need to handle these appropriately when separating out datetimes and usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2020-02-29, 6:00:23 PM] User 1: â˜º Twelve struck,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2020-02-29, 6:15:12 PM] User 1: â€Žvideo omitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "7   [2020-02-29, 6:00:23 PM] User 1: â˜º Twelve struck,\n",
       "8                          and one and two and three,\n",
       "9   and still we sat waiting silently for whatever...\n",
       "10    [2020-02-29, 6:15:12 PM] User 1: â€Žvideo omitted"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deepcopy into a working dataframe for preprocessing / cleaning\n",
    "\n",
    "messages = imported_messages.copy(deep=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Non-Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's work on extracting the datetime and username fields by leveraging [regular expressions](https://jakevdp.github.io/WhirlwindTourOfPython/14-strings-and-regular-expressions.html). Let's start with some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help us handle dates/times\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "\n",
    "# Library for regular expressions\n",
    "import regex\n",
    "\n",
    "# Library to handle emojis in text\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a helper function to aid us with extracting usernames and datetimes, then apply it to our dataframe. Here is further reading on [Regex Match Objects](https://docs.python.org/2.0/lib/match-objects.html) and [Python string splitting](https://docs.python.org/3/library/stdtypes.html#str.split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract datetime and username as text\n",
    "def extract_datetime_username(text):\n",
    "    \"\"\"\n",
    "    Note:   Requires regex module to be imported\n",
    "    Input:  String of text which may contain '[...]' text pattern\n",
    "            Eg: \"[2018-12-21, 2:55:51 AM] User 1: Messages to this chat and calls are now secured with end-to-end encryption.\"\n",
    "            \n",
    "    Output: Tuple of EITHER: (String to the right of the ': ' text pattern      Eg. \"Messages to this chat and calls are now secured with end-to-end encryption.\"\n",
    "                              String with contents of the '[...]' text pattern  Eg. \"2018-12-21, 2:55:51 AM\", \n",
    "                              String between the '[...]' and ': ' text patterns Eg. \"User 1\" )\n",
    "                              \n",
    "                     OR:     (String of of the original text if ''[...]'' pattern is not found,\n",
    "                              NaN,\n",
    "                              NaN)\n",
    "    \"\"\"\n",
    "    # Regex to find '[...]' pattern in text. date_time is a Regex Match Object\n",
    "    date_time = regex.search(r'.*\\[(.*)\\].*', text)\n",
    "    \n",
    "    # Output based on pattern search result\n",
    "    if date_time:\n",
    "        # Since we want to split only on the first occurrence of \"] \" and \": \" respectively, we pass in maxsplit=1 on str.split()\n",
    "        text_no_date = text.split(\"] \", maxsplit=1)[1]\n",
    "        text_split_on_user = text_no_date.split(\": \", maxsplit=1)\n",
    "        return (text_split_on_user[1], date_time.group(1), text_split_on_user[0])\n",
    "    else:\n",
    "        return (text, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28, 2:56:07 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28, 2:56:08 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28, 2:56:27 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw               date_time  \\\n",
       "0  From outside came the occasional cry of a nigh...  2020-02-28, 2:55:53 AM   \n",
       "1  and lool lool lool lool once at our very windo...  2020-02-28, 2:55:53 AM   \n",
       "2  \\ which told us that the cheetah was indeed at...  2020-02-28, 2:56:07 AM   \n",
       "3                                hah lmaoooo wooowww  2020-02-28, 2:56:08 AM   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...  2020-02-28, 2:56:27 AM   \n",
       "\n",
       "  username  \n",
       "0   User 1  \n",
       "1   User 2  \n",
       "2   User 2  \n",
       "3   User 2  \n",
       "4   User 1  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to our dataframe and extract out the datetimes and usernames\n",
    "messages['text_raw'], messages['date_time'], messages['username'] = zip(*messages['text_raw'].apply(extract_datetime_username))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>â˜º Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â€Žvideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    â˜º Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,                     NaN   \n",
       "9   and still we sat waiting silently for whatever...                     NaN   \n",
       "10                                     â€Žvideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8       NaN  \n",
       "9       NaN  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure functionality is as intended on rows with embedded line breaks\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's verify if there are any rows of text with none / NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_raw, date_time, username]\n",
       "Index: []"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['text_raw'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill in the NaN values in the 'date_time' and 'username' columns by considering those messages to have been sent by the user in the row above, at the time in the row above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>â˜º Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â€Žvideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    â˜º Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,  2020-02-29, 6:00:23 PM   \n",
       "9   and still we sat waiting silently for whatever...  2020-02-29, 6:00:23 PM   \n",
       "10                                     â€Žvideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8    User 1  \n",
       "9    User 1  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.fillna(method='ffill', inplace=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leverage Python's `datetime` module to convert our date_time column from a string to handy datetime objects (localized in my case to Toronto, Canada). <br>\n",
    "**Note:** Runtime on this appears to be abysmal, but performs acceptably on a sub 100k record dataset. This is probably a good area to attempt optimization later (Do we need expensive datetime objects? Do we need to localize? Which of the two methods is the bottleneck? Is there a better function other than df.apply()?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_TIMEZONE = timezone('America/Toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \n",
       "0 2020-02-28 02:55:53-05:00   User 1  \n",
       "1 2020-02-28 02:55:53-05:00   User 2  \n",
       "2 2020-02-28 02:56:07-05:00   User 2  \n",
       "3 2020-02-28 02:56:08-05:00   User 2  \n",
       "4 2020-02-28 02:56:27-05:00   User 1  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['date_time'] = messages['date_time'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d, %I:%M:%S %p'))\n",
    "messages['date_time'] = messages['date_time'].apply(lambda x: LOCAL_TIMEZONE.localize(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to work directly on the text data and make it more palatable for extracting insights from. We'll begin with library imports - primarily from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python String Library\n",
    "import string\n",
    "\n",
    "# NLTK for all our languarge processing needs (tokenization and stopword removal - lemmatization if our data ends up too 'muddy')\n",
    "import nltk\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "#from normalise import normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, let's outline what our [text preprocessing](https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html) pipeline will look like. <br><br>\n",
    "**Pipeline:**\n",
    "1. Tokenize each message\n",
    "2. Separate out emojis (**Note:** This might be revisited if/when I begin investigating sentiment analysis)                    \n",
    "3. Categorize each message type (text / picture / video / link)\n",
    "4. Clean text messages\n",
    "5. Normalize user-specific slang in text messages\n",
    "6. Remove stopwords from text messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:**<br>\n",
    "Let's [tokenize](https://www.geeksforgeeks.org/tokenize-text-using-nltk-python/) our corpus of text messages! In this case, we'll use NLTK's `TweetTokenizer`, since it is capable of splitting up emoji groupings and identifying html links as single tokens (see [here](https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7) for a brief comparison between NLTK tokenizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...  \n",
       "31  [made, it, impossible, for, me, to, tell, what...  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  \n",
       "33  [https://towardsdatascience.com/an-introductio...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "messages['text_processed'] = messages['text_raw'].apply(lambda x: tokenizer.tokenize(x))\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** <br>\n",
    "Let's now extract out the emojis from the text - through a helper function defined below. This will simplify the workload involved in extracting out emoji-related insights in our visualizations down the line. <br><br>\n",
    "**Note:** I had originally modified a solution found [here](https://stackoverflow.com/questions/49113909/split-and-count-emojis-and-words-in-a-given-string-in-python?noredirect=1&lq=1) to create a (very un-optimized!) solution that extracted emojis directly from the un-tokenized messages. However, this was before I discovered the magic of `TweetTokenizer`!\n",
    "[This site](https://www.regular-expressions.info/) and [this post](https://stackoverflow.com/questions/9928505/what-does-the-expression-x-match-when-inside-a-regex)  provided a lot of insight into understanding and using regex (despite it not being needed as heavily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for separating out emojis from the tokenized corpus\n",
    "def extract_emojis(tokenlist):\n",
    "    '''\n",
    "    Input:  List of tokenized strings (utf-8), containing emojis \n",
    "    Output: Tuple of the following: (list of non-emoji tokens from the input, list of all emoji tokens from the input)\n",
    "    '''\n",
    "    \n",
    "    list_emojis = []\n",
    "    list_text = []\n",
    "    \n",
    "    list_emojis = [token for token in tokenlist if any(char in emoji.UNICODE_EMOJI for char in token)]\n",
    "    list_text = [token for token in tokenlist if token not in list_emojis]\n",
    "    \n",
    "    return (list_text, list_emojis)\n",
    "\n",
    "#   **For reference, here's the original emoji list creation code without the one-liner list comprehension\n",
    "#    list_emojis = []\n",
    "#    for token in tokenlist:\n",
    "#        if any(char in emoji.UNICODE_EMOJI for char in token):  \n",
    "#            list_emojis += [token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>struck a match, and lashed furiously with his ...</td>\n",
       "      <td>2020-03-07 00:09:48-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[struck, a, match, ,, and, lashed, furiously, ...</td>\n",
       "      <td>[ðŸ˜†]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ðŸ˜¯ðŸ‘€</td>\n",
       "      <td>2020-03-07 00:09:56-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ‘€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"You see it, Watson?\" he yelled. \"You see it?\"</td>\n",
       "      <td>2020-03-08 17:10:08-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[\", You, see, it, ,, Watson, ?, \", he, yelled,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>But I saw nothing lmaoo. ðŸ˜¯</td>\n",
       "      <td>2020-03-08 17:10:29-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[But, I, saw, nothing, lmaoo, .]</td>\n",
       "      <td>[ðŸ˜¯]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>â€Žimage omitted</td>\n",
       "      <td>2020-03-08 17:15:24-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[â€Ž, image, omitted]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "24  struck a match, and lashed furiously with his ...   \n",
       "25                                                 ðŸ˜¯ðŸ‘€   \n",
       "26     \"You see it, Watson?\" he yelled. \"You see it?\"   \n",
       "27                         But I saw nothing lmaoo. ðŸ˜¯   \n",
       "28                                     â€Žimage omitted   \n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "24 2020-03-07 00:09:48-05:00   User 1   \n",
       "25 2020-03-07 00:09:56-05:00   User 1   \n",
       "26 2020-03-08 17:10:08-04:00   User 1   \n",
       "27 2020-03-08 17:10:29-04:00   User 1   \n",
       "28 2020-03-08 17:15:24-04:00   User 1   \n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis  \n",
       "24  [struck, a, match, ,, and, lashed, furiously, ...        [ðŸ˜†]  \n",
       "25                                                 []     [ðŸ˜¯, ðŸ‘€]  \n",
       "26  [\", You, see, it, ,, Watson, ?, \", he, yelled,...         []  \n",
       "27                   [But, I, saw, nothing, lmaoo, .]        [ðŸ˜¯]  \n",
       "28                                [â€Ž, image, omitted]         []  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...         []  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe and extract out the emojis\n",
    "messages['text_processed'], messages['emojis'] = zip(*messages['text_processed'].apply(extract_emojis))\n",
    "messages.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**<br>\n",
    "Since the WhatsApp chat log is text-only, any image or video media is represented as a message with the text *'image omitted'* or *'video omitted'* in it. In addition, shared links are sent as an individual message with the *'https://'* prefix and categorized into a single token by `TweetTokenizer`. We can use this information to categorize message types, as well as emptying the respective '*text_processed*' field for images and videos (since they aren't 'real' text messages).<br>\n",
    "**Note:** The 'image omitted' and 'text omitted' text has a non-printable unicode typesetting character ([\\u200e](https://www.fileformat.info/info/unicode/char/200e/index.htm)), hence the reason it is tokenized into 3 tokens, rather than the expected 2. Hidden / nonstandard characters such as this will be cleaned out in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u200e'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_raw'].iloc[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for categorizing messages into types (Warning, this function isn't very pythonic...)\n",
    "def categorize_message(tokenlist):\n",
    "    '''\n",
    "    Input:  Tokenized text string - i.e. list of words\n",
    "    Output: Tuple of the following: (String indicating type of message - 'image', 'video', 'link' or 'text'),\n",
    "                                     appropriate output token for the message type)\n",
    "    '''\n",
    "    # Identify links based on prefix\n",
    "    if (len(tokenlist) == 1):\n",
    "        if (tokenlist[0][:8] == 'https://'):\n",
    "            return ('link', tokenlist)\n",
    "    \n",
    "    # Identify images / video by default WhatsApp message (\"\\u200e image omitted\" or \"\\u200e video omitted\")\n",
    "    elif len(tokenlist) == 3:\n",
    "        if (tokenlist[2] == 'omitted'):\n",
    "            \n",
    "            if (tokenlist[1] == 'image'):\n",
    "                return ('image', [])\n",
    "            \n",
    "            elif (tokenlist[1] == 'video'):\n",
    "                return ('video', [])\n",
    "    \n",
    "    # Default is text\n",
    "    return ('text', tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[From, outside, came, the, occasional, cry, of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[and, lool, lool, lool, lool, once, at, our, v...</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[\\, which, told, us, that, the, cheetah, was, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hah, lmaoooo, wooowww]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[Far, away, we, could, hear, the, deep, tones,...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \n",
       "0  [From, outside, came, the, occasional, cry, of...         []     text  \n",
       "1  [and, lool, lool, lool, lool, once, at, our, v...  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text  \n",
       "2  [\\, which, told, us, that, the, cheetah, was, ...         []     text  \n",
       "3                            [hah, lmaoooo, wooowww]         []     text  \n",
       "4  [Far, away, we, could, hear, the, deep, tones,...     [ðŸ˜¯, â˜º]     text  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe\n",
    "messages['msg_type'], messages['text_processed'] = zip(*messages['text_processed'].apply(categorize_message))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video â€Žvideo omitted\n"
     ]
    }
   ],
   "source": [
    "print(messages['msg_type'].iloc[10], messages['text_raw'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** <br>\n",
    "Let's clean up the text by lowercasing all text, stripping leading / trailing whitespace, removing 'non-printable' characters (such punctuation and hidden characters such as '\\u200e' which may be embedded in our text messages). <br>\n",
    "**Note:** this may have the side effect of removing non-ascii characters, therefore might cause unintended behaviour if the message corpus contains **non-Latin (\"English\")** characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for cleaning up text (lowercasing all text + stripping whitespace + removing non-alphanumeric characters)\n",
    "def clean_text(tokenlist):\n",
    "    tokenlist_clean = []\n",
    "    \n",
    "    for token_raw in tokenlist:\n",
    "        token = token_raw.strip().lower()\n",
    "        token_clean = \"\".join(c for c in token if str.isalnum(c))\n",
    "        \n",
    "        if len(token_clean) > 0:\n",
    "            tokenlist_clean.append(token)\n",
    "            \n",
    "    return tokenlist_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[at, the, moment, when, holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [at, the, moment, when, holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [i, could, however, see, that, his, face, was,...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe, skipping any 'link' messages to preserve the html formatting, but cleaning the other message types\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(clean_text),\n",
    "                                      messages['text_processed'])\n",
    "\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7']\n"
     ]
    }
   ],
   "source": [
    "print(messages['text_processed'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** <br>\n",
    "Next, let's normalize our corpus to manage any slang and slang variants. The initial implementation attempted to use the `normalize` library found [here](https://github.com/EFord36/normalise), but processing runtime was infeasible for this dataset. As an alternative, I defined my own 'custom' normalizer to handle a user's 'chat-specific' slang. The normalizer primarily corrects slang words with repeated characters, as outlined in the comments below. The user can also define their own slang dictionary mappings in the auxiliary `Chat-History-User-Defined.ipynb` notebook. <br><br>\n",
    "**Note**: `TweetTokenizer` has a `reduce_len` parameter which accomplishes a similar functionality ([see here](https://www.nltk.org/api/nltk.tokenize.html) for details), but it treats words under the '3 repeated characters' limit as unique words, and is not user-customizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'Custom' normalizer:\n",
    "\n",
    "# 1) Define sets of 'slang' strings based on type of expected non-normalization, for example:\n",
    "# --- end-letter repeats (omgggg -> omg)\n",
    "# --- combination repeats (wooowww -> wow)\n",
    "# --- mid-letter repeats (looool -> lol)         [implemented via separate 'custom' dict instead]\n",
    "# --- two-letter repeats (hahahaha -> haha)      [implemented via separate 'custom' dict instead]\n",
    "# 2) Generate dicts which map slang variant to its 'root' form.\n",
    "# --- Will be specific for each set and have an 'upper bound' number of repeats\n",
    "# 3) Combine to a master 'normalization' dict. Define the custom normalization function to parse through the dict and evaluate feasibility of scaling up\n",
    "\n",
    "# Expected runtime O(n*m) where n = number of tokens in corpus, m = number of keys in master normalization lookup dict\n",
    "# Will be slow, but potentially m will at least 1-2 orders of magnitude smaller than using `normalise` library\n",
    "\n",
    "# Custom / User defined:\n",
    "# --- 'base' slang words and their 'type'\n",
    "# --- 'upper bound' on number of repeats for dict generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to generate dicts of slang strings based on their type\n",
    "def generate_slang_variants(SLANG_DICT, LIMIT = 5):\n",
    "    \"\"\"\n",
    "    Input:    LIMIT:            Integer defining maximum number of repeated letters.\n",
    "                                Default is 5 (i.e, 5 repeated single / double letters in the variant)\n",
    "              SLANG_DICT:       Dictionary of string: integer pairs.\n",
    "                                Strings are slang 'base' words. Integers are the slang variant 'type'defined below:\n",
    "                                1 == Repeating single final letter (eg. lmaooooo -> lmao)\n",
    "                                2 == Repeating double final letters (eg. wooooowwwww -> wow)\n",
    "                                \n",
    "    Output:   slang_lookup:     Dictionary of slang-variant : slang-root pairs\n",
    "    \"\"\"\n",
    "    slang_lookup = {}\n",
    "    \n",
    "    for root in SLANG_DICT: #root[-2:]\n",
    "                \n",
    "        if SLANG_DICT[root] == 1:\n",
    "            # Case 1: Repeat the single final letter up to limit. Add to final dictionary with root as value\n",
    "            for i in range(LIMIT):\n",
    "                variant = root + (root[-1]*i)\n",
    "                slang_lookup.update({variant : root})\n",
    "            \n",
    "        elif SLANG_DICT[root] == 2:\n",
    "            # Case 2: Generate combinations of both final letters up to limit. Add to final dictionary with root as value\n",
    "            for i in range(1, LIMIT+1):\n",
    "                for j in range(1, LIMIT+1):\n",
    "                    variant = root[:-2] + (root[-2]*i) + (root[-1]*j)\n",
    "                    slang_lookup.update({variant : root})\n",
    "    \n",
    "    return slang_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary function to normalize slang variants to their 'base' slang form\n",
    "def normalize_slang(tokenlist, slang_lookup):\n",
    "    \"\"\"\n",
    "    Input:    tokenlist:               Tokenized corpus to be parsed and normalized\n",
    "              slang_lookup:            Dictionary of slang-variant : slang-root pairs\n",
    "\n",
    "    Output:   tokenlist_normalized:    Normalized, tokenized corpus\n",
    "    \"\"\"\n",
    "    tokenlist_normalized = []\n",
    "    \n",
    "    for token in tokenlist:\n",
    "        if token in slang_lookup:\n",
    "            tokenlist_normalized.append(slang_lookup[token])\n",
    "        else:\n",
    "            tokenlist_normalized.append(token)\n",
    "    \n",
    "    return tokenlist_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final dictionary mapping slang variants to their 'base' slang word.\n",
    "slang_lookup = generate_slang_variants(SLANG_DICT, VARIANT_LIMIT)\n",
    "\n",
    "# 'Custom' slang variants are added to this final dictionary as well\n",
    "slang_lookup.update(SLANG_SPECIAL_CASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[at, the, moment, when, holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [at, the, moment, when, holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [i, could, however, see, that, his, face, was,...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe and normalize slang on non-link messages\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(lambda x: normalize_slang(x, slang_lookup)),\n",
    "                                      messages['text_processed'])\n",
    "#messages['text_processed'] = messages['text_processed'].apply(lambda x: normalize_slang(x, slang_lookup))\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:**<br>\n",
    "Finally, let's remove common [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) from our tokenized and cleaned (non-link) messages. This will ensure our data isn't polluted by common-use words. The user can also define additional stopwords in the `Chat-History-User-Defined.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard set of stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Add user-defined custom stopwords to set\n",
    "stopwords_set = stopwords_set | STOPWORDS_EXTRA\n",
    "\n",
    "# List comprehension helper function to remove stopwords\n",
    "def remove_stopwords(tokenlist):\n",
    "    return [word.lower() for word in tokenlist if word.lower() not in stopwords_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[outside, came, occasional, cry, night-bird]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[window, long, drawn, catlike, whine]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[told, us, cheetah, indeed, liberty]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hahaha, lmao, wow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \n",
       "0       [outside, came, occasional, cry, night-bird]         []     text  \n",
       "1              [window, long, drawn, catlike, whine]  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text  \n",
       "2               [told, us, cheetah, indeed, liberty]         []     text  \n",
       "3                                [hahaha, lmao, wow]         []     text  \n",
       "4  [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe and remove stopwords on non-link messages\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(remove_stopwords),\n",
    "                                      messages['text_processed'])\n",
    "#messages['text_processed'] = messages['text_processed'].apply(remove_stopwords)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[moment, holmes, struck, light, heard, low, cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[sudden, glare, flashing, weary, eyes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, impossible, tell, friend, lashed, savag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [moment, holmes, struck, light, heard, low, cl...         []     text  \n",
       "30             [sudden, glare, flashing, weary, eyes]         []     text  \n",
       "31  [made, impossible, tell, friend, lashed, savag...         []     text  \n",
       "32  [could, however, see, face, deadly, pale, fill...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7']\n"
     ]
    }
   ],
   "source": [
    "print(messages['text_processed'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've reduced our text messages to their keywords, lets add a column counting the number of keywords per message (which can be a basic, analagous metric for message length or complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[outside, came, occasional, cry, night-bird]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[window, long, drawn, catlike, whine]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[told, us, cheetah, indeed, liberty]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hahaha, lmao, wow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \\\n",
       "0       [outside, came, occasional, cry, night-bird]         []     text   \n",
       "1              [window, long, drawn, catlike, whine]  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text   \n",
       "2               [told, us, cheetah, indeed, liberty]         []     text   \n",
       "3                                [hahaha, lmao, wow]         []     text   \n",
       "4  [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text   \n",
       "\n",
       "   keyword_count  \n",
       "0              5  \n",
       "1              5  \n",
       "2              5  \n",
       "3              3  \n",
       "4              8  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['keyword_count'] = messages['text_processed'].apply(len)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part! Let's make a list of potential data vizualizations, in the context of a two-person WhatsApp conversation:\n",
    "1. General stats, including:\n",
    "    - Messages totals per person\n",
    "    - Image / Video / Link totals per person\n",
    "    - Most messages in a day\n",
    "    - Longest message\n",
    "2. Daily (or weekly if too noisy) time series for number of messages. Can annotate based on known life events.\n",
    "3. Word-based statistics, including:\n",
    "    - Most used words, broken down by person. Can annotate or draw attention to 'interesting' or 'key' words.\n",
    "    - Longest word used by each person.\n",
    "4. Most used emojis, broken down by person.\n",
    "5. Average message qty by day of week - can also extend to identify which hours were the busiest\n",
    "6. Longest consecutive days without messages sent by either person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep track of which dataframes can be used for each vizualization - and create new ones if needed (TBD if not yet investigated or implemented)!\n",
    "1. `messages` and `timeseries`\n",
    "2. `timeseries`\n",
    "3. `text_expanded_by_user`\n",
    "4. `emoji_expanded_by_user`\n",
    "5. TBD (`timeseries`)\n",
    "6. TBD (`messages`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 1:**\n",
    "- Total messages sent by user and category can be easily pivoted out from the `messages` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>username</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username  User 1  User 2\n",
       "msg_type                \n",
       "image        1.0     NaN\n",
       "link         NaN     1.0\n",
       "text        18.0    13.0\n",
       "video        1.0     NaN"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(messages, values='text_processed', index='msg_type', columns='username', aggfunc=len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, we can pivot `messages` to create a dataframe with records [grouped by day](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects) and broken down by user + type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:55:53-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:56:07-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:56:08-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:56:27-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29 17:56:40-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2     \n",
       "msg_type                   image text video   link text\n",
       "date_time                                              \n",
       "2020-02-28 02:55:53-05:00    0.0  1.0   0.0    0.0  1.0\n",
       "2020-02-28 02:56:07-05:00    0.0  0.0   0.0    0.0  1.0\n",
       "2020-02-28 02:56:08-05:00    0.0  0.0   0.0    0.0  1.0\n",
       "2020-02-28 02:56:27-05:00    0.0  1.0   0.0    0.0  0.0\n",
       "2020-02-29 17:56:40-05:00    0.0  0.0   0.0    0.0  1.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot\n",
    "timeseries_raw = pd.pivot_table(messages,\n",
    "                                values='text_processed',\n",
    "                                index='date_time', \n",
    "                                columns=['username', 'msg_type'], \n",
    "                                aggfunc=len).fillna(0)\n",
    "timeseries_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-01 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-08 00:00:00-05:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-29 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-07 00:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2      total\n",
       "msg_type                   image text video   link text      \n",
       "date_time                                                    \n",
       "2020-03-01 00:00:00-05:00    0.0  4.0   0.0    0.0  4.0   8.0\n",
       "2020-03-08 00:00:00-05:00    1.0  4.0   0.0    1.0  2.0   8.0\n",
       "2020-02-29 00:00:00-05:00    0.0  4.0   1.0    0.0  1.0   6.0\n",
       "2020-02-28 00:00:00-05:00    0.0  2.0   0.0    0.0  3.0   5.0\n",
       "2020-03-07 00:00:00-05:00    0.0  2.0   0.0    0.0  2.0   4.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample dataframe by day, create total column, and sort from most to least messages\n",
    "timeseries = timeseries_raw.resample('D').sum()\n",
    "timeseries['total'] = timeseries.sum(axis=1)\n",
    "timeseries.sort_values(by='total', ascending=False, inplace=True)\n",
    "timeseries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can leverage the 'keyword_count' column to identify what the longest message is and its details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>--a very gentle, soothing sound, like that of ...</td>\n",
       "      <td>2020-03-02 22:20:32-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[gentle, soothing, sound, like, small, jet, st...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[moment, holmes, struck, light, heard, low, cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29 18:00:23-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[still, sat, waiting, silently, whatever, migh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "21  --a very gentle, soothing sound, like that of ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "4   ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "9   and still we sat waiting silently for whatever...   \n",
       "\n",
       "                   date_time username  \\\n",
       "21 2020-03-02 22:20:32-05:00   User 2   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "4  2020-02-28 02:56:27-05:00   User 1   \n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "9  2020-02-29 18:00:23-05:00   User 1   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \\\n",
       "21  [gentle, soothing, sound, like, small, jet, st...         []     text   \n",
       "32  [could, however, see, face, deadly, pale, fill...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text   \n",
       "4   [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text   \n",
       "29  [moment, holmes, struck, light, heard, low, cl...         []     text   \n",
       "9   [still, sat, waiting, silently, whatever, migh...         []     text   \n",
       "\n",
       "    keyword_count  \n",
       "21             10  \n",
       "32              9  \n",
       "4               8  \n",
       "29              8  \n",
       "9               7  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.nlargest(5, 'keyword_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 2:**<br>\n",
    "The `timeseries` dataframe can be used to create a 'run chart' of day-by-day message counts. We can further group into weeks if the visualization is too cluttered / noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 3:**<br>\n",
    "- Creating 'by user' visualizations require us to have access to the individual tokens in `messages[text_processed]`. We can explode out each token to a new row and preserve usernames (in a new dataframe) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>occasional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>night-bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username text_processed\n",
       "0   User 1        outside\n",
       "0   User 1           came\n",
       "0   User 1     occasional\n",
       "0   User 1            cry\n",
       "0   User 1     night-bird"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_expanded = messages[['username','text_processed']].explode('text_processed').dropna()\n",
    "text_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pivot this data such that we obtain rows for counts of each unique word, broken down per user. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lmao</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hahaha</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>see</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sound</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>struck</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gentle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>could</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hour</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_processed  User 1  User 2  total\n",
       "0           lmao     4.0     1.0    5.0\n",
       "1         hahaha     3.0     1.0    4.0\n",
       "2            see     2.0     1.0    3.0\n",
       "3          sound     2.0     1.0    3.0\n",
       "4         struck     2.0     1.0    3.0\n",
       "5          heard     1.0     2.0    3.0\n",
       "6         gentle     1.0     1.0    2.0\n",
       "7          smell     1.0     1.0    2.0\n",
       "8          could     1.0     1.0    2.0\n",
       "9           hour     1.0     1.0    2.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot\n",
    "text_expanded_by_user = text_expanded.pivot_table(text_expanded, \n",
    "                                                  index='text_processed', \n",
    "                                                  columns='username', \n",
    "                                                  aggfunc=len).fillna(0)\n",
    "\n",
    "# Create and populate a 'total' column\n",
    "text_expanded_by_user['total'] = text_expanded_by_user.sum(axis=1)\n",
    "\n",
    "# Sort by most common words\n",
    "text_expanded_by_user.sort_values(by='total', ascending=False, inplace=True)\n",
    "        \n",
    "# Re-index dataframe and fix column naming\n",
    "text_expanded_by_user = text_expanded_by_user.reset_index()\n",
    "text_expanded_by_user.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "text_expanded_by_user.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finding the longest used word requires a bit of additional manipulation of the `text_expanded_by_user` dataset. The wordlist includes url text so we need to lookup each word in an English language dictionary (`words` from `nltk.corpus` in this case - it isn't the best wordlist but it probably isn't worth the effort to import a large library for the sake of a one-line visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "wordset = set(words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_processed    immediately\n",
       "User 1                      0\n",
       "User 2                      1\n",
       "total                       1\n",
       "word_len                   11\n",
       "english_word             True\n",
       "Name: 108, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column to capture word lengths (will be used later)\n",
    "text_expanded_by_user['word_len'] = text_expanded_by_user['text_processed'].apply(len)\n",
    "\n",
    "# Sort text_expanded_by_user based on word length\n",
    "#wordlist = pd.DataFrame(text_expanded_by_user.sort_values(by='word_len', ascending=False))\n",
    "\n",
    "# Add a column to determine word presence in English\n",
    "text_expanded_by_user[\"english_word\"] = text_expanded_by_user[\"text_processed\"].apply(lambda x: x in wordset)\n",
    "\n",
    "# Sort by word length and English-only words, and select longest word\n",
    "text_expanded_by_user[text_expanded_by_user['english_word']].sort_values(by='word_len', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 4:**<br>\n",
    "We can repeat the process above to obtain a similar dataframe for emojis. **Note:** Need to'de-emojize' before pivoting, since many identical emojis were unnecessarily represented differently in unicode. To display as emojis in visualizations, must 're-emojize' the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>â˜º</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username emojis\n",
       "1   User 2      ðŸ˜¯\n",
       "1   User 2      ðŸ˜¯\n",
       "1   User 2      ðŸ˜¯\n",
       "4   User 1      ðŸ˜¯\n",
       "4   User 1      â˜º"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_expanded = messages[['username','emojis']].explode('emojis').dropna()\n",
    "emoji_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emojis</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>total</th>\n",
       "      <th>emojis_disp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:hushed_face:</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:loudly_crying_face:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ðŸ˜­</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:eyes:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ðŸ‘€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:grinning_squinting_face:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ðŸ˜†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:smiling_face:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>â˜º</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>:frowning_face:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>â˜¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>:grinning_face_with_smiling_eyes:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ðŸ˜„</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              emojis  User 1  User 2  total emojis_disp\n",
       "0                      :hushed_face:     7.0     4.0   11.0           ðŸ˜¯\n",
       "1               :loudly_crying_face:     0.0     7.0    7.0           ðŸ˜­\n",
       "2                             :eyes:     2.0     0.0    2.0           ðŸ‘€\n",
       "3          :grinning_squinting_face:     2.0     0.0    2.0           ðŸ˜†\n",
       "4                     :smiling_face:     2.0     0.0    2.0           â˜º\n",
       "5                    :frowning_face:     1.0     0.0    1.0           â˜¹\n",
       "6  :grinning_face_with_smiling_eyes:     0.0     1.0    1.0           ðŸ˜„"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De-emoji in-progress dataframe\n",
    "emoji_expanded['emojis'] = emoji_expanded['emojis'].apply(emoji.demojize)\n",
    "\n",
    "# Pivot\n",
    "emoji_expanded_by_user = emoji_expanded.pivot_table(emoji_expanded, \n",
    "                                                  index='emojis', \n",
    "                                                  columns='username', \n",
    "                                                  aggfunc=len).fillna(0)\n",
    "\n",
    "# Create and populate a 'total' column\n",
    "emoji_expanded_by_user['total'] = emoji_expanded_by_user.sum(axis=1)\n",
    "\n",
    "# Sort by most common emojis\n",
    "emoji_expanded_by_user.sort_values(by='total', ascending=False, inplace=True)\n",
    "\n",
    "# Re-index dataframe and fix column naming\n",
    "emoji_expanded_by_user = emoji_expanded_by_user.reset_index()\n",
    "emoji_expanded_by_user.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "# 'Re-emoji' in a separate column\n",
    "emoji_expanded_by_user['emojis_disp'] = emoji_expanded_by_user['emojis'].apply(emoji.emojize)\n",
    "\n",
    "emoji_expanded_by_user.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ˜¯'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(emoji_expanded_by_user['emojis'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 5:**<br>\n",
    "To get a day-of-the-week aggregate of messaging data, we'll need to adopt a similar resampling approach as the `timeseries` dataframe, but with a bit more granularity (sampling by hour so we can average, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th colspan=\"3\" halign=\"left\">User 1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msg_type</th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>video</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-28 02:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 03:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 04:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 05:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 06:00:00-05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "username                  User 1            User 2      total\n",
       "msg_type                   image text video   link text      \n",
       "date_time                                                    \n",
       "2020-02-28 02:00:00-05:00    0.0  2.0   0.0    0.0  3.0   NaN\n",
       "2020-02-28 03:00:00-05:00    0.0  0.0   0.0    0.0  0.0   NaN\n",
       "2020-02-28 04:00:00-05:00    0.0  0.0   0.0    0.0  0.0   NaN\n",
       "2020-02-28 05:00:00-05:00    0.0  0.0   0.0    0.0  0.0   NaN\n",
       "2020-02-28 06:00:00-05:00    0.0  0.0   0.0    0.0  0.0   NaN"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the timeseries_raw dataframe used earlier by hour, and create total column, and sort from most to least messages\n",
    "timeseries_weekday = timeseries_raw.resample('H').sum()\n",
    "timeseries_weekday['total'] = timeseries.sum(axis=1)\n",
    "#timeseries.sort_values(by='total', ascending=False, inplace=True)\n",
    "timeseries_weekday.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe can now be grouped by weekday, using averaged message totals for each hour of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIP\n",
    "#timeseries_weekday[\"day_name\"] = timeseries_weekday.index.values.day_name\n",
    "\n",
    "#times = pd.to_datetime(df.timestamp_col)\n",
    "#weekdays = pd.DataFrame(timeseries_weekday.index.values)\n",
    "#df.groupby([times.hour, times.minute]).value_col.sum()\n",
    "#weekdays.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasciproj]",
   "language": "python",
   "name": "conda-env-datasciproj-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
