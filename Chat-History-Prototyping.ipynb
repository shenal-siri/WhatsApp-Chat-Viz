{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Chat History Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a *work-in-progress* notebook for prototyping my chat log data visualization tool. Code here has been minimally refactored - the intent is to develop an MVP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by importing our bread-and-butter data and visualization libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the custom dictionaries defined in `Chat-History-Custom-Functs.ipynb` (which will be used in the text normalization process). Feel free to edit the dictionaries based on the desired normalization in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Chat-History-User-Defined.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the WhatsApp chat log (exported from an iOS device) to a dataframe and make a deepcopy for us to try out all of our preprocessing on. <br>\n",
    "**Note:** For privacy purposes, the chat log available on GitHub is much shorter and consists of dummy text, albeit maintaining WhatsApp's export style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 1: From outside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 2: and lool lool...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2020-02-28, 2:56:07 AM] User 2: \\ which told ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2020-02-28, 2:56:27 AM] User 1: ðŸ˜¯ Far away we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw\n",
       "0  [2020-02-28, 2:55:53 AM] User 1: From outside ...\n",
       "1  [2020-02-28, 2:55:53 AM] User 2: and lool lool...\n",
       "2  [2020-02-28, 2:56:07 AM] User 2: \\ which told ...\n",
       "3  [2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...\n",
       "4  [2020-02-28, 2:56:27 AM] User 1: ðŸ˜¯ Far away we..."
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Whatsapp chat log to a dataframe\n",
    "\n",
    "imported_messages = pd.read_csv('chat.txt', delimiter='\\n', skiprows=[0], names = ['text_raw'])\n",
    "imported_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[2020-03-08, 05:20:32 PM] User 2: At the momen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[2020-03-08, 05:45:56 PM] User 1: lool but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[2020-03-08, 05:50:34 PM] User 2: I could, how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[2020-03-08, 05:52:12 PM] User 2: https://towa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "29  [2020-03-08, 05:20:32 PM] User 2: At the momen...\n",
       "30  [2020-03-08, 05:45:56 PM] User 1: lool but the...\n",
       "31  made it impossible for me to tell what it was ...\n",
       "32  [2020-03-08, 05:50:34 PM] User 2: I could, how...\n",
       "33  [2020-03-08, 05:52:12 PM] User 2: https://towa..."
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imported_messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Using '\\n' as the delimiter results in messages with embedded line breaks escaping to new rows in the dataframe. These rows will not have the '*\\[datetime\\] username: text*' pattern seen in other rows, so we need to handle these appropriately when separating out datetimes and usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2020-02-29, 6:00:23 PM] User 1: â˜º Twelve struck,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2020-02-29, 6:15:12 PM] User 1: â€Žvideo omitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "7   [2020-02-29, 6:00:23 PM] User 1: â˜º Twelve struck,\n",
       "8                          and one and two and three,\n",
       "9   and still we sat waiting silently for whatever...\n",
       "10    [2020-02-29, 6:15:12 PM] User 1: â€Žvideo omitted"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deepcopy into a working dataframe for preprocessing / cleaning\n",
    "\n",
    "messages = imported_messages.copy(deep=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Non-Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's work on extracting the datetime and username fields by leveraging [regular expressions](https://jakevdp.github.io/WhirlwindTourOfPython/14-strings-and-regular-expressions.html). Let's start with some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help us handle dates/times\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "\n",
    "# Library for regular expressions\n",
    "import regex\n",
    "\n",
    "# Library to handle emojis in text\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a helper function to aid us with extracting usernames and datetimes, then apply it to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract datetime and username as text\n",
    "def extract_datetime_username(text):\n",
    "    \"\"\"\n",
    "    Note:   Requires regex module to be imported\n",
    "    Input:  String of text which may contain '[...]' text pattern\n",
    "    Output: Tuple of the following: (String to the right of the ': ' text pattern      OR original text string ,\n",
    "                                     String with contents of the '[...]' text pattern  OR NaN , \n",
    "                                     String between the '[...]' and ': ' text patterns OR NaN )\n",
    "    \"\"\"\n",
    "    # Regex to find '[...]' pattern in text\n",
    "    date_time = regex.search(r'.*\\[(.*)\\].*', text)\n",
    "    \n",
    "    # Output based on pattern search result\n",
    "    if date_time:\n",
    "        text_remainder = text.split(\"] \")[1]\n",
    "        text_username = text_remainder.split(\": \")\n",
    "        return (text_username[1], date_time.group(1), text_username[0])\n",
    "    else:\n",
    "        return (text, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28, 2:56:07 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28, 2:56:08 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28, 2:56:27 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw               date_time  \\\n",
       "0  From outside came the occasional cry of a nigh...  2020-02-28, 2:55:53 AM   \n",
       "1  and lool lool lool lool once at our very windo...  2020-02-28, 2:55:53 AM   \n",
       "2  \\ which told us that the cheetah was indeed at...  2020-02-28, 2:56:07 AM   \n",
       "3                                hah lmaoooo wooowww  2020-02-28, 2:56:08 AM   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...  2020-02-28, 2:56:27 AM   \n",
       "\n",
       "  username  \n",
       "0   User 1  \n",
       "1   User 2  \n",
       "2   User 2  \n",
       "3   User 2  \n",
       "4   User 1  "
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to our dataframe and extract out the datetimes and usernames\n",
    "messages['text_raw'], messages['date_time'], messages['username'] = zip(*messages['text_raw'].apply(extract_datetime_username))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>â˜º Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â€Žvideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    â˜º Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,                     NaN   \n",
       "9   and still we sat waiting silently for whatever...                     NaN   \n",
       "10                                     â€Žvideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8       NaN  \n",
       "9       NaN  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure functionality is as intended on rows with embedded line breaks\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's verify if there are any rows of text with none / NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_raw, date_time, username]\n",
       "Index: []"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['text_raw'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill in the NaN values in the 'date_time' and 'username' columns by considering those messages to have been sent by the user in the row above, at the time in the row above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>â˜º Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â€Žvideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    â˜º Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,  2020-02-29, 6:00:23 PM   \n",
       "9   and still we sat waiting silently for whatever...  2020-02-29, 6:00:23 PM   \n",
       "10                                     â€Žvideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8    User 1  \n",
       "9    User 1  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.fillna(method='ffill', inplace=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leverage Python's `datetime` module to convert our date_time column from a string to handy datetime objects (localized in my case to Toronto, Canada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_timezone = timezone('America/Toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \n",
       "0 2020-02-28 02:55:53-05:00   User 1  \n",
       "1 2020-02-28 02:55:53-05:00   User 2  \n",
       "2 2020-02-28 02:56:07-05:00   User 2  \n",
       "3 2020-02-28 02:56:08-05:00   User 2  \n",
       "4 2020-02-28 02:56:27-05:00   User 1  "
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['date_time'] = messages['date_time'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d, %I:%M:%S %p'))\n",
    "messages['date_time'] = messages['date_time'].apply(lambda x: local_timezone.localize(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to work directly on the text data and make it more palatable for extracting insights from. We'll begin with library imports - primarily from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python String Library\n",
    "import string\n",
    "\n",
    "# NLTK for all our languarge processing needs (tokenization and stopword removal - lemmatization if our data ends up too 'muddy')\n",
    "import nltk\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "#from normalise import normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, let's outline what our [text preprocessing](https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html) pipeline will look like. <br><br>\n",
    "**Pipeline:**\n",
    "1. Tokenize each message\n",
    "2. Separate out emojis (**Note:** This might be revisited if/when I begin investigating sentiment analysis)                    \n",
    "3. Categorize each message type (text / picture / video / link)\n",
    "4. Clean text messages\n",
    "5. Normalize user-specific slang in text messages\n",
    "6. Remove stopwords from text messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:**<br>\n",
    "Let's [tokenize](https://www.geeksforgeeks.org/tokenize-text-using-nltk-python/) our corpus of text messages! In this case, we'll use NLTK's `TweetTokenizer`, since it is capable of splitting up emoji groupings and identifying html links as single tokens (see [here](https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7) for a brief comparison between NLTK tokenizers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...  \n",
       "31  [made, it, impossible, for, me, to, tell, what...  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  \n",
       "33  [https://towardsdatascience.com/an-introductio...  "
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "messages['text_processed'] = messages['text_raw'].apply(lambda x: tokenizer.tokenize(x))\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** <br>\n",
    "Let's now extract out the emojis from the text - through a helper function defined below. This will simplify the workload involved in extracting out emoji-related insights in our visualizations down the line. <br><br>\n",
    "**Note:** I had originally modified a solution found [here](https://stackoverflow.com/questions/49113909/split-and-count-emojis-and-words-in-a-given-string-in-python?noredirect=1&lq=1) to create a (very un-optimized!) solution that extracted emojis directly from the un-tokenized messages. However, this was before I discovered the magic of `TweetTokenizer`!\n",
    "[This site](https://www.regular-expressions.info/) and [this post](https://stackoverflow.com/questions/9928505/what-does-the-expression-x-match-when-inside-a-regex)  provided a lot of insight into understanding and using regex (despite it not being needed as heavily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for separating out emojis from the tokenized corpus\n",
    "def extract_emojis(tokenlist):\n",
    "    '''\n",
    "    Input:  List of tokenized strings (utf-8), containing emojis \n",
    "    Output: Tuple of the following: (list of non-emoji tokens from the input, list of all emoji tokens from the input)\n",
    "    '''\n",
    "    \n",
    "    list_emojis = []\n",
    "    list_text = []\n",
    "    \n",
    "    list_emojis = [token for token in tokenlist if any(char in emoji.UNICODE_EMOJI for char in token)]\n",
    "    list_text = [token for token in tokenlist if token not in list_emojis]\n",
    "    \n",
    "    return (list_text, list_emojis)\n",
    "\n",
    "#   **For reference, here's the original emoji list creation code without the one-liner list comprehension\n",
    "#    list_emojis = []\n",
    "#    for token in tokenlist:\n",
    "#        if any(char in emoji.UNICODE_EMOJI for char in token):  \n",
    "#            list_emojis += [token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>struck a match, and lashed furiously with his ...</td>\n",
       "      <td>2020-03-07 00:09:48-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[struck, a, match, ,, and, lashed, furiously, ...</td>\n",
       "      <td>[ðŸ˜†]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ðŸ˜¯ðŸ‘€</td>\n",
       "      <td>2020-03-07 00:09:56-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ‘€]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"You see it, Watson?\" he yelled. \"You see it?\"</td>\n",
       "      <td>2020-03-08 17:10:08-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[\", You, see, it, ,, Watson, ?, \", he, yelled,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>But I saw nothing lmaoo. ðŸ˜¯</td>\n",
       "      <td>2020-03-08 17:10:29-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[But, I, saw, nothing, lmaoo, .]</td>\n",
       "      <td>[ðŸ˜¯]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>â€Žimage omitted</td>\n",
       "      <td>2020-03-08 17:15:24-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[â€Ž, image, omitted]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "24  struck a match, and lashed furiously with his ...   \n",
       "25                                                 ðŸ˜¯ðŸ‘€   \n",
       "26     \"You see it, Watson?\" he yelled. \"You see it?\"   \n",
       "27                         But I saw nothing lmaoo. ðŸ˜¯   \n",
       "28                                     â€Žimage omitted   \n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "24 2020-03-07 00:09:48-05:00   User 1   \n",
       "25 2020-03-07 00:09:56-05:00   User 1   \n",
       "26 2020-03-08 17:10:08-04:00   User 1   \n",
       "27 2020-03-08 17:10:29-04:00   User 1   \n",
       "28 2020-03-08 17:15:24-04:00   User 1   \n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis  \n",
       "24  [struck, a, match, ,, and, lashed, furiously, ...        [ðŸ˜†]  \n",
       "25                                                 []     [ðŸ˜¯, ðŸ‘€]  \n",
       "26  [\", You, see, it, ,, Watson, ?, \", he, yelled,...         []  \n",
       "27                   [But, I, saw, nothing, lmaoo, .]        [ðŸ˜¯]  \n",
       "28                                [â€Ž, image, omitted]         []  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...         []  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []  "
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe and extract out the emojis\n",
    "messages['text_processed'], messages['emojis'] = zip(*messages['text_processed'].apply(extract_emojis))\n",
    "messages.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**<br>\n",
    "Since the WhatsApp chat log is text-only, any image or video media is represented as a message with the text *'image omitted'* or *'video omitted'* in it. In addition, shared links are sent as an individual message with the *'https://'* prefix and categorized into a single token by `TweetTokenizer`. We can use this information to categorize message types, as well as emptying the respective '*text_processed*' field for images and videos (since they aren't 'real' text messages).<br>\n",
    "**Note:** The 'image omitted' and 'text omitted' text has a non-printable unicode typesetting character ([\\u200e](https://www.fileformat.info/info/unicode/char/200e/index.htm)), hence the reason it is tokenized into 3 tokens, rather than the expected 2. Hidden / nonstandard characters such as this will be cleaned out in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\u200e'"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_raw'].iloc[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for categorizing messages into types (Warning, this function isn't very pythonic...)\n",
    "def categorize_message(tokenlist):\n",
    "    '''\n",
    "    Input:  Tokenized text string - i.e. list of words\n",
    "    Output: Tuple of the following: (String indicating type of message - 'image', 'video', 'link' or 'text'),\n",
    "                                     appropriate output token for the message type)\n",
    "    '''\n",
    "    # Identify links based on prefix\n",
    "    if (len(tokenlist) == 1):\n",
    "        if (tokenlist[0][:8] == 'https://'):\n",
    "            return ('link', tokenlist)\n",
    "    \n",
    "    # Identify images / video by default WhatsApp message (\"\\u200e image omitted\" or \"\\u200e video omitted\")\n",
    "    elif len(tokenlist) == 3:\n",
    "        if (tokenlist[2] == 'omitted'):\n",
    "            \n",
    "            if (tokenlist[1] == 'image'):\n",
    "                return ('image', [])\n",
    "            \n",
    "            elif (tokenlist[1] == 'video'):\n",
    "                return ('video', [])\n",
    "    \n",
    "    # Default is text\n",
    "    return ('text', tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[From, outside, came, the, occasional, cry, of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[and, lool, lool, lool, lool, once, at, our, v...</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[\\, which, told, us, that, the, cheetah, was, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hah, lmaoooo, wooowww]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[Far, away, we, could, hear, the, deep, tones,...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \n",
       "0  [From, outside, came, the, occasional, cry, of...         []     text  \n",
       "1  [and, lool, lool, lool, lool, once, at, our, v...  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text  \n",
       "2  [\\, which, told, us, that, the, cheetah, was, ...         []     text  \n",
       "3                            [hah, lmaoooo, wooowww]         []     text  \n",
       "4  [Far, away, we, could, hear, the, deep, tones,...     [ðŸ˜¯, â˜º]     text  "
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe\n",
    "messages['msg_type'], messages['text_processed'] = zip(*messages['text_processed'].apply(categorize_message))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video â€Žvideo omitted\n"
     ]
    }
   ],
   "source": [
    "print(messages['msg_type'].iloc[10], messages['text_raw'].iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[At, the, moment, when, Holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[I, could, ,, however, ,, see, that, his, face...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [At, the, moment, when, Holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [I, could, ,, however, ,, see, that, his, face...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** <br>\n",
    "Let's clean up the text by lowercasing all text, stripping leading / trailing whitespace, removing 'non-printable' characters (such punctuation and hidden characters such as '\\u200e' which may be embedded in our text messages). <br>\n",
    "**Note:** this may have the side effect of removing non-ascii characters, therefore might cause unintended behaviour if the message corpus contains **non-Latin (\"English\")** characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for cleaning up text (lowercasing all text + stripping whitespace + removing non-alphanumeric characters)\n",
    "def clean_text(tokenlist):\n",
    "    tokenlist_clean = []\n",
    "    \n",
    "    for token_raw in tokenlist:\n",
    "        token = token_raw.strip().lower()\n",
    "        token_clean = \"\".join(c for c in token if str.isalnum(c))\n",
    "        \n",
    "        if len(token_clean) > 0:\n",
    "            tokenlist_clean.append(token)\n",
    "            \n",
    "    return tokenlist_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[at, the, moment, when, holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [at, the, moment, when, holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [i, could, however, see, that, his, face, was,...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe, skipping any 'link' messages to preserve the html formatting, but cleaning the other message types\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(clean_text),\n",
    "                                      messages['text_processed'])\n",
    "\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7']\n"
     ]
    }
   ],
   "source": [
    "print(messages['text_processed'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:** <br>\n",
    "Next, let's normalize our corpus to manage any slang and slang variants. The initial implementation attempted to use the `normalize` library found [here](https://github.com/EFord36/normalise), but processing runtime was infeasible for this dataset. As an alternative, I defined my own 'custom' normalizer to handle a user's 'chat-specific' slang. The normalizer primarily corrects slang words with repeated characters, as outlined in the comments below. The user can also define their own slang dictionary mappings in the auxiliary `Chat-History-User-Defined.ipynb` notebook. <br><br>\n",
    "**Note**: `TweetTokenizer` has a `reduce_len` parameter which accomplishes a similar functionality ([see here](https://www.nltk.org/api/nltk.tokenize.html) for details), but it treats words under the '3 repeated characters' limit as unique words, and is not user-customizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'Custom' normalizer:\n",
    "\n",
    "# 1) Define sets of 'slang' strings based on type of expected non-normalization, for example:\n",
    "# --- end-letter repeats (omgggg -> omg)\n",
    "# --- combination repeats (wooowww -> wow)\n",
    "# --- mid-letter repeats (looool -> lol)         [implemented via separate 'custom' dict instead]\n",
    "# --- two-letter repeats (hahahaha -> haha)      [implemented via separate 'custom' dict instead]\n",
    "# 2) Generate dicts which map slang variant to its 'root' form.\n",
    "# --- Will be specific for each set and have an 'upper bound' number of repeats\n",
    "# 3) Combine to a master 'normalization' dict. Define the custom normalization function to parse through the dict and evaluate feasibility of scaling up\n",
    "\n",
    "# Expected runtime O(n*m) where n = number of tokens in corpus, m = number of keys in master normalization lookup dict\n",
    "# Will be slow, but potentially m will at least 1-2 orders of magnitude smaller than using `normalise` library\n",
    "\n",
    "# Custom / User defined:\n",
    "# --- 'base' slang words and their 'type'\n",
    "# --- 'upper bound' on number of repeats for dict generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to generate dicts of slang strings based on their type\n",
    "def generate_slang_variants(SLANG_DICT, LIMIT = 5):\n",
    "    \"\"\"\n",
    "    Input:    LIMIT:            Integer defining maximum number of repeated letters.\n",
    "                                Default is 5 (i.e, 5 repeated single / double letters in the variant)\n",
    "              SLANG_DICT:       Dictionary of string: integer pairs.\n",
    "                                Strings are slang 'base' words. Integers are the slang variant 'type'defined below:\n",
    "                                1 == Repeating single final letter (eg. lmaooooo -> lmao)\n",
    "                                2 == Repeating double final letters (eg. wooooowwwww -> wow)\n",
    "                                \n",
    "    Output:   slang_lookup:     Dictionary of slang-variant : slang-root pairs\n",
    "    \"\"\"\n",
    "    slang_lookup = {}\n",
    "    \n",
    "    for root in SLANG_DICT: #root[-2:]\n",
    "                \n",
    "        if SLANG_DICT[root] == 1:\n",
    "            # Case 1: Repeat the single final letter up to limit. Add to final dictionary with root as value\n",
    "            for i in range(LIMIT):\n",
    "                variant = root + (root[-1]*i)\n",
    "                slang_lookup.update({variant : root})\n",
    "            \n",
    "        elif SLANG_DICT[root] == 2:\n",
    "            # Case 2: Generate combinations of both final letters up to limit. Add to final dictionary with root as value\n",
    "            for i in range(1, LIMIT+1):\n",
    "                for j in range(1, LIMIT+1):\n",
    "                    variant = root[:-2] + (root[-2]*i) + (root[-1]*j)\n",
    "                    slang_lookup.update({variant : root})\n",
    "    \n",
    "    return slang_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary function to normalize slang variants to their 'base' slang form\n",
    "def normalize_slang(tokenlist, slang_lookup):\n",
    "    \"\"\"\n",
    "    Input:    tokenlist:               Tokenized corpus to be parsed and normalized\n",
    "              slang_lookup:            Dictionary of slang-variant : slang-root pairs\n",
    "\n",
    "    Output:   tokenlist_normalized:    Normalized, tokenized corpus\n",
    "    \"\"\"\n",
    "    tokenlist_normalized = []\n",
    "    \n",
    "    for token in tokenlist:\n",
    "        if token in slang_lookup:\n",
    "            tokenlist_normalized.append(slang_lookup[token])\n",
    "        else:\n",
    "            tokenlist_normalized.append(token)\n",
    "    \n",
    "    return tokenlist_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final dictionary mapping slang variants to their 'base' slang word.\n",
    "slang_lookup = generate_slang_variants(SLANG_DICT, VARIANT_LIMIT)\n",
    "\n",
    "# 'Custom' slang variants are added to this final dictionary as well\n",
    "slang_lookup.update(SLANG_SPECIAL_CASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[at, the, moment, when, holmes, struck, the, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[lool, but, the, sudden, glare, lool, lool, fl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [at, the, moment, when, holmes, struck, the, l...         []     text  \n",
       "30  [lool, but, the, sudden, glare, lool, lool, fl...         []     text  \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []     text  \n",
       "32  [i, could, however, see, that, his, face, was,...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe and normalize slang on non-link messages\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(lambda x: normalize_slang(x, slang_lookup)),\n",
    "                                      messages['text_processed'])\n",
    "#messages['text_processed'] = messages['text_processed'].apply(lambda x: normalize_slang(x, slang_lookup))\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:**<br>\n",
    "Finally, let's remove common [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) from our tokenized and cleaned (non-link) messages. This will ensure our data isn't polluted by common-use words. The user can also define additional stopwords in the `Chat-History-User-Defined.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard set of stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "\n",
    "# Add user-defined custom stopwords to set\n",
    "stopwords_set = stopwords_set | STOPWORDS_EXTRA\n",
    "\n",
    "# List comprehension helper function to remove stopwords\n",
    "def remove_stopwords(tokenlist):\n",
    "    return [word.lower() for word in tokenlist if word.lower() not in stopwords_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[outside, came, occasional, cry, night-bird]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and lool lool lool lool once at our very windo...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[window, long, drawn, catlike, whine]</td>\n",
       "      <td>[ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\ which told us that the cheetah was indeed at...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[told, us, cheetah, indeed, liberty]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hahaha, lmao, wow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ðŸ˜¯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, could, hear, deep, tones, parish, ...</td>\n",
       "      <td>[ðŸ˜¯, â˜º]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and lool lool lool lool once at our very windo...   \n",
       "2  \\ which told us that the cheetah was indeed at...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  ðŸ˜¯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis msg_type  \n",
       "0       [outside, came, occasional, cry, night-bird]         []     text  \n",
       "1              [window, long, drawn, catlike, whine]  [ðŸ˜¯, ðŸ˜¯, ðŸ˜¯]     text  \n",
       "2               [told, us, cheetah, indeed, liberty]         []     text  \n",
       "3                                [hahaha, lmao, wow]         []     text  \n",
       "4  [far, away, could, hear, deep, tones, parish, ...     [ðŸ˜¯, â˜º]     text  "
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply function to dataframe and remove stopwords on non-link messages\n",
    "messages['text_processed'] = np.where(messages['msg_type'] != 'link',\n",
    "                                      messages['text_processed'].apply(remove_stopwords),\n",
    "                                      messages['text_processed'])\n",
    "#messages['text_processed'] = messages['text_processed'].apply(remove_stopwords)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>At the moment when Holmes struck the light I h...</td>\n",
       "      <td>2020-03-08 17:20:32-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[moment, holmes, struck, light, heard, low, cl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lool but the sudden glare lool lool flashing i...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[sudden, glare, flashing, weary, eyes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, impossible, tell, friend, lashed, savag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[ðŸ˜­, ðŸ˜­, ðŸ˜­]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>https://towardsdatascience.com/an-introduction...</td>\n",
       "      <td>2020-03-08 17:52:12-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[https://towardsdatascience.com/an-introductio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "29  At the moment when Holmes struck the light I h...   \n",
       "30  lool but the sudden glare lool lool flashing i...   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33  https://towardsdatascience.com/an-introduction...   \n",
       "\n",
       "                   date_time username  \\\n",
       "29 2020-03-08 17:20:32-04:00   User 2   \n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 17:52:12-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis msg_type  \n",
       "29  [moment, holmes, struck, light, heard, low, cl...         []     text  \n",
       "30             [sudden, glare, flashing, weary, eyes]         []     text  \n",
       "31  [made, impossible, tell, friend, lashed, savag...         []     text  \n",
       "32  [could, however, see, face, deadly, pale, fill...  [ðŸ˜­, ðŸ˜­, ðŸ˜­]     text  \n",
       "33  [https://towardsdatascience.com/an-introductio...         []     link  "
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://towardsdatascience.com/an-introduction-to-tweettokenizer-for-processing-tweets-9879389f8fe7']\n"
     ]
    }
   ],
   "source": [
    "print(messages['text_processed'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part! Let's make a list of potential data vizualizations, in the context of a two-person WhatsApp conversation:\n",
    "1. General stats (Messages totals per person, image / media totals per person, most messages in a day, longest message length etc.)\n",
    "2. Daily (or weekly if too noisy) time series for number of messages. Can annotate based on known life events.\n",
    "3. Most used words, broken down by person. Can highlight 'key' words.\n",
    "4. Most used emojis, broken down by person.\n",
    "5. Longest word used by each person.\n",
    "6. Average message qty by day of week - can also extend to identify which hours were the busiest\n",
    "7. Longest consecutive days without messages sent by either person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep track of which dataframes can be used for each vizualization - and create new ones if needed (TBD if not yet investigated / implemented)!\n",
    "1. TBD\n",
    "2. `messages`\n",
    "3. `text_expanded_by_user`\n",
    "4. `emoji_expanded_by_user`\n",
    "5. `text_expanded_by_user`\n",
    "6. `messages`\n",
    "7. `messages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 'by user' visualizations require us to have access to the individual tokens in `messages[text_processed]`. We can explode out each token to a new row and preserve usernames (in a new dataframe) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>came</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>occasional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "      <td>night-bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username text_processed\n",
       "0   User 1        outside\n",
       "0   User 1           came\n",
       "0   User 1     occasional\n",
       "0   User 1            cry\n",
       "0   User 1     night-bird"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_expanded = messages[['username','text_processed']].explode('text_processed').dropna()\n",
    "text_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pivot this data such that we obtain rows for counts of each unique word, broken down per user. This can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lmao</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hahaha</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>see</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sound</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>struck</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>heard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gentle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>smell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>could</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hour</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lashed</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>holmes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>light</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>suddenly</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>long</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>seemed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>silent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>silently</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>saw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>savagely</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>quarter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>room</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>quarters</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>parish</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>pale</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>outside</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>one</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>oil</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>occasional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>nothing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>night-bird</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>next</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>movement</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>small</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>another</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>someone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>moment</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>window</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>whistle</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>whine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>whatever</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>weary</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>watson</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>waiting</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ventilator</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>vanished</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>us</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>two</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>twelve</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tones</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>told</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>three</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>though</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>tell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sudden</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>succeeded</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>stronger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>strong</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_processed  User 1  User 2  total\n",
       "0            lmao     4.0     1.0    5.0\n",
       "1          hahaha     3.0     1.0    4.0\n",
       "2             see     2.0     1.0    3.0\n",
       "3           sound     2.0     1.0    3.0\n",
       "4          struck     2.0     1.0    3.0\n",
       "5           heard     1.0     2.0    3.0\n",
       "6          gentle     1.0     1.0    2.0\n",
       "7           smell     1.0     1.0    2.0\n",
       "8           could     1.0     1.0    2.0\n",
       "9            hour     1.0     1.0    2.0\n",
       "10         lashed     2.0     0.0    2.0\n",
       "11         holmes     0.0     2.0    2.0\n",
       "12          light     1.0     1.0    2.0\n",
       "13       suddenly     2.0     0.0    2.0\n",
       "14           long     1.0     1.0    2.0\n",
       "15            sat     2.0     0.0    2.0\n",
       "16         seemed     1.0     0.0    1.0\n",
       "17         silent     1.0     0.0    1.0\n",
       "18       silently     1.0     0.0    1.0\n",
       "19            saw     1.0     0.0    1.0\n",
       "20       savagely     1.0     0.0    1.0\n",
       "21        quarter     0.0     1.0    1.0\n",
       "22           room     0.0     1.0    1.0\n",
       "23       quarters     1.0     0.0    1.0\n",
       "24         parish     1.0     0.0    1.0\n",
       "25           pale     0.0     1.0    1.0\n",
       "26        outside     1.0     0.0    1.0\n",
       "27            one     1.0     0.0    1.0\n",
       "28            oil     0.0     1.0    1.0\n",
       "29     occasional     1.0     0.0    1.0\n",
       "30        nothing     1.0     0.0    1.0\n",
       "31     night-bird     1.0     0.0    1.0\n",
       "32           next     0.0     1.0    1.0\n",
       "33       movement     1.0     0.0    1.0\n",
       "34          small     0.0     1.0    1.0\n",
       "35        another     1.0     0.0    1.0\n",
       "36        someone     0.0     1.0    1.0\n",
       "37         moment     0.0     1.0    1.0\n",
       "38            wow     0.0     1.0    1.0\n",
       "39         window     0.0     1.0    1.0\n",
       "40        whistle     0.0     1.0    1.0\n",
       "41          whine     0.0     1.0    1.0\n",
       "42       whatever     1.0     0.0    1.0\n",
       "43          weary     1.0     0.0    1.0\n",
       "44         watson     1.0     0.0    1.0\n",
       "45        waiting     1.0     0.0    1.0\n",
       "46     ventilator     1.0     0.0    1.0\n",
       "47       vanished     0.0     1.0    1.0\n",
       "48             us     0.0     1.0    1.0\n",
       "49            two     1.0     0.0    1.0\n",
       "50         twelve     1.0     0.0    1.0\n",
       "51          tones     1.0     0.0    1.0\n",
       "52           told     0.0     1.0    1.0\n",
       "53          three     1.0     0.0    1.0\n",
       "54         though     1.0     0.0    1.0\n",
       "55           tell     1.0     0.0    1.0\n",
       "56         sudden     1.0     0.0    1.0\n",
       "57      succeeded     0.0     1.0    1.0\n",
       "58       stronger     1.0     0.0    1.0\n",
       "59         strong     0.0     1.0    1.0"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot\n",
    "text_expanded_by_user = text_expanded.pivot_table(text_expanded, \n",
    "                                                  index='text_processed', \n",
    "                                                  columns='username', \n",
    "                                                  aggfunc=len).fillna(0)\n",
    "\n",
    "# Create and populate a 'total' column\n",
    "text_expanded_by_user['total'] = 0\n",
    "\n",
    "for column in text_expanded_by_user:\n",
    "    if column != 'total':\n",
    "        text_expanded_by_user['total'] += text_expanded_by_user[column]\n",
    "\n",
    "# Sort by most common words\n",
    "text_expanded_by_user.sort_values(by='total', ascending=False, inplace=True)\n",
    "        \n",
    "# Re-index dataframe and fix column naming\n",
    "text_expanded_by_user = text_expanded_by_user.reset_index()\n",
    "text_expanded_by_user.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "text_expanded_by_user.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this process to obtain a similar dataframe for emojis. **Note:** Need to'de-emojize' before pivoting, since many identical emojis were unnecessarily represented differently in unicode. To display as emojis in visualizations, must 're-emojize' the emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>ðŸ˜¯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User 1</td>\n",
       "      <td>â˜º</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  username emojis\n",
       "1   User 2      ðŸ˜¯\n",
       "1   User 2      ðŸ˜¯\n",
       "1   User 2      ðŸ˜¯\n",
       "4   User 1      ðŸ˜¯\n",
       "4   User 1      â˜º"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_expanded = messages[['username','emojis']].explode('emojis').dropna()\n",
    "emoji_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emojis</th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:hushed_face:</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:loudly_crying_face:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:eyes:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:grinning_squinting_face:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:smiling_face:</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>:frowning_face:</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>:grinning_face_with_smiling_eyes:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              emojis  User 1  User 2  total\n",
       "0                      :hushed_face:     7.0     4.0   11.0\n",
       "1               :loudly_crying_face:     0.0     7.0    7.0\n",
       "2                             :eyes:     2.0     0.0    2.0\n",
       "3          :grinning_squinting_face:     2.0     0.0    2.0\n",
       "4                     :smiling_face:     2.0     0.0    2.0\n",
       "5                    :frowning_face:     1.0     0.0    1.0\n",
       "6  :grinning_face_with_smiling_eyes:     0.0     1.0    1.0"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De-emoji in-progress dataframe\n",
    "emoji_expanded['emojis'] = emoji_expanded['emojis'].apply(emoji.demojize)\n",
    "\n",
    "# Pivot\n",
    "emoji_expanded_by_user = emoji_expanded.pivot_table(emoji_expanded, \n",
    "                                                  index='emojis', \n",
    "                                                  columns='username', \n",
    "                                                  aggfunc=len).fillna(0)\n",
    "\n",
    "# Create and populate a 'total' column\n",
    "emoji_expanded_by_user['total'] = 0\n",
    "\n",
    "for column in emoji_expanded_by_user:\n",
    "    if column != 'total':\n",
    "        emoji_expanded_by_user['total'] += emoji_expanded_by_user[column]\n",
    "\n",
    "# Sort by most common emojis\n",
    "emoji_expanded_by_user.sort_values(by='total', ascending=False, inplace=True)\n",
    "\n",
    "# Re-index dataframe and fix column naming\n",
    "emoji_expanded_by_user = emoji_expanded_by_user.reset_index()\n",
    "emoji_expanded_by_user.rename_axis(None, axis=1, inplace=True)\n",
    "\n",
    "emoji_expanded_by_user.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ðŸ˜¯'"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(emoji_expanded_by_user['emojis'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two more dataframes that can be fed into some of our target vizualizations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a. Message totals per person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasciproj]",
   "language": "python",
   "name": "conda-env-datasciproj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
