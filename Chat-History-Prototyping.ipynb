{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhatsApp Chat History Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a *work-in-progress* notebook for prototyping my chat log data visualization tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start off by importing our bread-and-butter data and visualization libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the custom dictionaries defined in `Chat-History-Custom-Functs.ipynb` (which will be used in the text normalization process). Feel free to edit the dictionaries based on the desired normalization in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Chat-History-Custom-Functs.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in the WhatsApp chat log (exported from an iOS device) to a dataframe and make a deepcopy for us to try out all of our preprocessing on. <br>\n",
    "**Note:** For privacy purposes, the chat log available on GitHub is much shorter and consists of dummy text, albeit maintaining WhatsApp's export style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 1: From outside ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2020-02-28, 2:55:53 AM] User 2: and once at o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2020-02-28, 2:56:07 AM] User 2: \\n which told...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2020-02-28, 2:56:27 AM] User 1: 沽ｯ Far away we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw\n",
       "0  [2020-02-28, 2:55:53 AM] User 1: From outside ...\n",
       "1  [2020-02-28, 2:55:53 AM] User 2: and once at o...\n",
       "2  [2020-02-28, 2:56:07 AM] User 2: \\n which told...\n",
       "3  [2020-02-28, 2:56:08 AM] User 2: hah lmaoooo w...\n",
       "4  [2020-02-28, 2:56:27 AM] User 1: 沽ｯ Far away we..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Whatsapp chat log to a dataframe\n",
    "\n",
    "imported_messages = pd.read_csv('chat.txt', delimiter='\\n', skiprows=[0], names = ['text_raw'])\n",
    "imported_messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Using '\\n' as the delimiter results in messages with embedded line breaks escaping to new rows in the dataframe. These rows will not have the '*\\[datetime\\] username: text*' pattern seen in other rows, so we need to handle these appropriately when separating out datetimes and usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[2020-02-29, 6:00:23 PM] User 1: 笘ｺ Twelve struck,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2020-02-29, 6:15:12 PM] User 1: 窶思ideo omitted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw\n",
       "7   [2020-02-29, 6:00:23 PM] User 1: 笘ｺ Twelve struck,\n",
       "8                          and one and two and three,\n",
       "9   and still we sat waiting silently for whatever...\n",
       "10    [2020-02-29, 6:15:12 PM] User 1: 窶思ideo omitted"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deepcopy into a working dataframe for preprocessing / cleaning\n",
    "\n",
    "messages = imported_messages.copy(deep=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Non-Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now let's work on extracting the datetime and username fields by leveraging [regular expressions](https://jakevdp.github.io/WhirlwindTourOfPython/14-strings-and-regular-expressions.html). Let's start with some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to help us handle dates/times\n",
    "import datetime as dt\n",
    "from pytz import timezone\n",
    "\n",
    "# Library for regular expressions\n",
    "import regex\n",
    "\n",
    "# Library to handle emojis in text\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a helper function to aid us with extracting usernames and datetimes, then apply it to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract datetime and username as text\n",
    "def extract_datetime_username(text):\n",
    "    \"\"\"\n",
    "    Note:   Requires regex module to be imported\n",
    "    Input:  String of text which may contain '[...]' text pattern\n",
    "    Output: Tuple of the following: (String to the right of the ': ' text pattern      OR original text string ,\n",
    "                                     String with contents of the '[...]' text pattern  OR NaN , \n",
    "                                     String between the '[...]' and ': ' text patterns OR NaN )\n",
    "    \"\"\"\n",
    "    # Regex to find '[...]' pattern in text\n",
    "    date_time = regex.search(r'.*\\[(.*)\\].*', text)\n",
    "    \n",
    "    # Output based on pattern search result\n",
    "    if date_time:\n",
    "        text_remainder = text.split(\"] \")[1]\n",
    "        text_username = text_remainder.split(\": \")\n",
    "        return (text_username[1], date_time.group(1), text_username[0])\n",
    "    else:\n",
    "        return (text, np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>2020-02-28, 2:55:53 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>2020-02-28, 2:56:07 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28, 2:56:08 AM</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>沽ｯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28, 2:56:27 AM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw               date_time  \\\n",
       "0  From outside came the occasional cry of a nigh...  2020-02-28, 2:55:53 AM   \n",
       "1  and once at our very window a long drawn catli...  2020-02-28, 2:55:53 AM   \n",
       "2  \\n which told us that the cheetah was indeed a...  2020-02-28, 2:56:07 AM   \n",
       "3                                hah lmaoooo wooowww  2020-02-28, 2:56:08 AM   \n",
       "4  沽ｯ Far away we could hear the deep tones of the...  2020-02-28, 2:56:27 AM   \n",
       "\n",
       "  username  \n",
       "0   User 1  \n",
       "1   User 2  \n",
       "2   User 2  \n",
       "3   User 2  \n",
       "4   User 1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to our dataframe and extract out the datetimes and usernames\n",
    "messages['text_raw'], messages['date_time'], messages['username'] = zip(*messages['text_raw'].apply(extract_datetime_username))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>笘ｺ Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>窶思ideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    笘ｺ Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,                     NaN   \n",
       "9   and still we sat waiting silently for whatever...                     NaN   \n",
       "10                                     窶思ideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8       NaN  \n",
       "9       NaN  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure functionality is as intended on rows with embedded line breaks\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed, let's verify if there are any rows of text with none / NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_raw, date_time, username]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['text_raw'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fill in the NaN values in the 'date_time' and 'username' columns by considering those messages to have been sent by the user in the row above, at the time in the row above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>笘ｺ Twelve struck,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29, 6:00:23 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>窶思ideo omitted</td>\n",
       "      <td>2020-02-29, 6:15:12 PM</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw               date_time  \\\n",
       "7                                    笘ｺ Twelve struck,  2020-02-29, 6:00:23 PM   \n",
       "8                          and one and two and three,  2020-02-29, 6:00:23 PM   \n",
       "9   and still we sat waiting silently for whatever...  2020-02-29, 6:00:23 PM   \n",
       "10                                     窶思ideo omitted  2020-02-29, 6:15:12 PM   \n",
       "\n",
       "   username  \n",
       "7    User 1  \n",
       "8    User 1  \n",
       "9    User 1  \n",
       "10   User 1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.fillna(method='ffill', inplace=True)\n",
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leverage Python's `datetime` module to convert our date_time column from a string to handy datetime objects (localized in my case to Toronto, Canada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_timezone = timezone('America/Toronto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>沽ｯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and once at our very window a long drawn catli...   \n",
       "2  \\n which told us that the cheetah was indeed a...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  沽ｯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \n",
       "0 2020-02-28 02:55:53-05:00   User 1  \n",
       "1 2020-02-28 02:55:53-05:00   User 2  \n",
       "2 2020-02-28 02:56:07-05:00   User 2  \n",
       "3 2020-02-28 02:56:08-05:00   User 2  \n",
       "4 2020-02-28 02:56:27-05:00   User 1  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['date_time'] = messages['date_time'].apply(lambda x: dt.datetime.strptime(x, '%Y-%m-%d, %I:%M:%S %p'))\n",
    "messages['date_time'] = messages['date_time'].apply(lambda x: local_timezone.localize(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for emojis: let's create another helper function to extract emojis into a separate dataframe column.<br>\n",
    "**Note:** This was a more complicated endeavour than I had initially anticipated. I modified a solution found [here](https://stackoverflow.com/questions/49113909/split-and-count-emojis-and-words-in-a-given-string-in-python?noredirect=1&lq=1) to create a (very un-optimized!) solution. [This](https://www.regular-expressions.info/) site and [this](https://stackoverflow.com/questions/9928505/what-does-the-expression-x-match-when-inside-a-regex) post also helped!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract and process emojis\n",
    "def extract_emojis(text):\n",
    "    '''\n",
    "    Input:  String (utf-8 encoding) containing emojis \n",
    "    Output: Tuple of the following: (original string with emojis removed, list of all emojis found in the string)\n",
    "    '''\n",
    "    # Use regex to split up our string. '\\X' captures composite unicode emojis as a single emoji\n",
    "    data = regex.findall(r'\\X',text)    \n",
    "    \n",
    "    # Create a list of all emojis present in data**\n",
    "    all_emojis = [symbol for symbol in data if any(char in emoji.UNICODE_EMOJI for char in symbol)]\n",
    "            \n",
    "    # Remove emojis from the given text\n",
    "    for emjs in all_emojis:\n",
    "        text = text.replace(emjs, '') \n",
    "\n",
    "    return (text, all_emojis)\n",
    "\n",
    "\n",
    "#   **For reference, here's the original emoji list creation code without the one-liner list comprehension\n",
    "#    all_emojis = []\n",
    "#    for word in data:\n",
    "#        if any(char in emoji.UNICODE_EMOJI for char in word):  \n",
    "#            all_emojis += [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>[沽ｯ, 沽ｯ, 沽ｯ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>沽ｯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>Far away we could hear the deep tones of the ...</td>\n",
       "      <td>[沽ｯ, 笘ｺ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and once at our very window a long drawn catli...   \n",
       "2  \\n which told us that the cheetah was indeed a...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  沽ｯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis  \n",
       "0  From outside came the occasional cry of a nigh...         []  \n",
       "1  and once at our very window a long drawn catli...  [沽ｯ, 沽ｯ, 沽ｯ]  \n",
       "2  \\n which told us that the cheetah was indeed a...         []  \n",
       "3                                hah lmaoooo wooowww         []  \n",
       "4   Far away we could hear the deep tones of the ...     [沽ｯ, 笘ｺ]  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe and extract out the emojis\n",
    "messages['text_processed'], messages['emojis'] = zip(*messages['text_raw'].apply(extract_emojis))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to work directly on the text data and make it more palatable for extracting insights from. We'll begin with library imports - primarily from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python String Library\n",
    "import string\n",
    "\n",
    "# NLTK for all our languarge processing needs (tokenization and stopword removal - lemmatization if our data ends up too 'muddy')\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "from normalise import normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed:\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, let's outline what our [text preprocessing](https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html) pipeline will look like. <br><br>\n",
    "**Pipeline:**\n",
    "1. Remove noise from each message\n",
    "2. Tokenize each message\n",
    "3. Categorize each message type (text / picture / video) (*Note: voice call missed / video call missed not implemented yet*)\n",
    "4. Normalize the corpus of messages\n",
    "5. Remove stopwords from each message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** <br>\n",
    "Since we've removed all the emojis, let's clean up the text further by lowercasing all text and removing 'non-printable' characters (co-opting [this solution](https://stackoverflow.com/questions/1342000/how-to-make-the-python-interpreter-correctly-handle-non-ascii-characters-in-stri)).\n",
    "**Note:** this may have the side effect of removing non-ascii characters, therefore might cause unintended behaviour if the message corpus contains **non-Latin (\"English\")** characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for lowercasing all text\n",
    "def convert_lowercase(s):\n",
    "    return s.lower()\n",
    "\n",
    "# Define function for removing non-printable characters\n",
    "def remove_non_printables(s):\n",
    "    return \"\".join(x for x in s if str.isprintable(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video omitted'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply it to our dataframe to clean the raw text data\n",
    "messages['text_processed'] = messages['text_processed'].apply(remove_non_printables)\n",
    "messages['text_processed'] = messages['text_processed'].apply(convert_lowercase)\n",
    "messages.iloc[10]['text_processed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now before we process our text data any further, let's store each message's length (since this is the best time to capture a 'true-to-typed-out' character count, excluding emojis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>from outside came the occasional cry of a nigh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>[沽ｯ, 沽ｯ, 沽ｯ]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>[]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>沽ｯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>far away we could hear the deep tones of the ...</td>\n",
       "      <td>[沽ｯ, 笘ｺ]</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and once at our very window a long drawn catli...   \n",
       "2  \\n which told us that the cheetah was indeed a...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  沽ｯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis  \\\n",
       "0  from outside came the occasional cry of a nigh...         []   \n",
       "1  and once at our very window a long drawn catli...  [沽ｯ, 沽ｯ, 沽ｯ]   \n",
       "2  \\n which told us that the cheetah was indeed a...         []   \n",
       "3                                hah lmaoooo wooowww         []   \n",
       "4   far away we could hear the deep tones of the ...     [沽ｯ, 笘ｺ]   \n",
       "\n",
       "   text_str_length  \n",
       "0               52  \n",
       "1               55  \n",
       "2               56  \n",
       "3               19  \n",
       "4               59  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_str_length'] = messages['text_processed'].apply(len)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>笘ｺ Twelve struck,</td>\n",
       "      <td>2020-02-29 18:00:23-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>twelve struck,</td>\n",
       "      <td>[笘ｺ]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>2020-02-29 18:00:23-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>and one and two and three,</td>\n",
       "      <td>[]</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>2020-02-29 18:00:23-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>and still we sat waiting silently for whatever...</td>\n",
       "      <td>[]</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>窶思ideo omitted</td>\n",
       "      <td>2020-02-29 18:15:12-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>video omitted</td>\n",
       "      <td>[]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "7                                    笘ｺ Twelve struck,   \n",
       "8                          and one and two and three,   \n",
       "9   and still we sat waiting silently for whatever...   \n",
       "10                                     窶思ideo omitted   \n",
       "\n",
       "                   date_time username  \\\n",
       "7  2020-02-29 18:00:23-05:00   User 1   \n",
       "8  2020-02-29 18:00:23-05:00   User 1   \n",
       "9  2020-02-29 18:00:23-05:00   User 1   \n",
       "10 2020-02-29 18:15:12-05:00   User 1   \n",
       "\n",
       "                                       text_processed emojis  text_str_length  \n",
       "7                                      twelve struck,    [笘ｺ]               15  \n",
       "8                          and one and two and three,     []               26  \n",
       "9   and still we sat waiting silently for whatever...     []               61  \n",
       "10                                      video omitted     []               13  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.iloc[7:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:**<br>\n",
    "Now, let's [tokenize](https://www.geeksforgeeks.org/tokenize-text-using-nltk-python/) our corpus of text messages! In this case, we'll use a [regex tokenizer](https://kite.com/python/answers/how-to-remove-all-punctuation-marks-with-nltk-in-python) to ignore punctuation and only select words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[from, outside, came, the, occasional, cry, of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[and, once, at, our, very, window, a, long, dr...</td>\n",
       "      <td>[沽ｯ, 沽ｯ, 沽ｯ]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[n, which, told, us, that, the, cheetah, was, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hah, lmaoooo, wooowww]</td>\n",
       "      <td>[]</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>沽ｯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, we, could, hear, the, deep, tones,...</td>\n",
       "      <td>[沽ｯ, 笘ｺ]</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and once at our very window a long drawn catli...   \n",
       "2  \\n which told us that the cheetah was indeed a...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  沽ｯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis  \\\n",
       "0  [from, outside, came, the, occasional, cry, of...         []   \n",
       "1  [and, once, at, our, very, window, a, long, dr...  [沽ｯ, 沽ｯ, 沽ｯ]   \n",
       "2  [n, which, told, us, that, the, cheetah, was, ...         []   \n",
       "3                            [hah, lmaoooo, wooowww]         []   \n",
       "4  [far, away, we, could, hear, the, deep, tones,...     [沽ｯ, 笘ｺ]   \n",
       "\n",
       "   text_str_length  \n",
       "0               52  \n",
       "1               55  \n",
       "2               56  \n",
       "3               19  \n",
       "4               59  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "messages['text_processed'] = messages['text_processed'].apply(lambda x: tokenizer.tokenize(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**<br>\n",
    "Since the WhatsApp chat log is text-only, any image or video media is represented as a message with the text *'image omitted'* or *'video omitted'* in it. We can extract this information into a separate column, as well as emptying the respective `text_processed` field (since they aren't 'real' messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding image and video messages\n",
    "def find_message_type(tokenlist):\n",
    "    '''\n",
    "    Input:  Tokenized text string - i.e. list of words)\n",
    "    Output: Tuple of the following: (String indicating type of message ['image', 'video', or 'text')],\n",
    "                                     appropriate output token for the message type\n",
    "    '''\n",
    "    if len(tokenlist) == 2:\n",
    "        if (tokenlist[1] == 'omitted'):\n",
    "            \n",
    "            if (tokenlist[0] == 'image'):\n",
    "                return ('image', [])\n",
    "            \n",
    "            elif (tokenlist[0] == 'video'):\n",
    "                return ('video', [])\n",
    "                        \n",
    "    return ('text', tokenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From outside came the occasional cry of a nigh...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[from, outside, came, the, occasional, cry, of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>52</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and once at our very window a long drawn catli...</td>\n",
       "      <td>2020-02-28 02:55:53-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[and, once, at, our, very, window, a, long, dr...</td>\n",
       "      <td>[沽ｯ, 沽ｯ, 沽ｯ]</td>\n",
       "      <td>55</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n which told us that the cheetah was indeed a...</td>\n",
       "      <td>2020-02-28 02:56:07-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[n, which, told, us, that, the, cheetah, was, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>56</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hah lmaoooo wooowww</td>\n",
       "      <td>2020-02-28 02:56:08-05:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[hah, lmaoooo, wooowww]</td>\n",
       "      <td>[]</td>\n",
       "      <td>19</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>沽ｯ Far away we could hear the deep tones of the...</td>\n",
       "      <td>2020-02-28 02:56:27-05:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[far, away, we, could, hear, the, deep, tones,...</td>\n",
       "      <td>[沽ｯ, 笘ｺ]</td>\n",
       "      <td>59</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_raw  \\\n",
       "0  From outside came the occasional cry of a nigh...   \n",
       "1  and once at our very window a long drawn catli...   \n",
       "2  \\n which told us that the cheetah was indeed a...   \n",
       "3                                hah lmaoooo wooowww   \n",
       "4  沽ｯ Far away we could hear the deep tones of the...   \n",
       "\n",
       "                  date_time username  \\\n",
       "0 2020-02-28 02:55:53-05:00   User 1   \n",
       "1 2020-02-28 02:55:53-05:00   User 2   \n",
       "2 2020-02-28 02:56:07-05:00   User 2   \n",
       "3 2020-02-28 02:56:08-05:00   User 2   \n",
       "4 2020-02-28 02:56:27-05:00   User 1   \n",
       "\n",
       "                                      text_processed     emojis  \\\n",
       "0  [from, outside, came, the, occasional, cry, of...         []   \n",
       "1  [and, once, at, our, very, window, a, long, dr...  [沽ｯ, 沽ｯ, 沽ｯ]   \n",
       "2  [n, which, told, us, that, the, cheetah, was, ...         []   \n",
       "3                            [hah, lmaoooo, wooowww]         []   \n",
       "4  [far, away, we, could, hear, the, deep, tones,...     [沽ｯ, 笘ｺ]   \n",
       "\n",
       "   text_str_length msg_type  \n",
       "0               52     text  \n",
       "1               55     text  \n",
       "2               56     text  \n",
       "3               19     text  \n",
       "4               59     text  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['msg_type'], messages['text_processed'] = zip(*messages['text_processed'].apply(find_message_type))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>but the sudden glare flashing into my weary eyes</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[but, the, sudden, glare, flashing, into, my, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>84</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[沽ｭ, 沽ｭ, 沽ｭ]</td>\n",
       "      <td>88</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>窶皿issed video call</td>\n",
       "      <td>2020-03-08 18:20:13-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[missed, video, call]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>窶皿issed voice call</td>\n",
       "      <td>2020-03-08 18:22:23-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[missed, voice, call]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "30   but the sudden glare flashing into my weary eyes   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33                                 窶皿issed video call   \n",
       "34                                 窶皿issed voice call   \n",
       "\n",
       "                   date_time username  \\\n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 18:20:13-04:00   User 2   \n",
       "34 2020-03-08 18:22:23-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis  \\\n",
       "30  [but, the, sudden, glare, flashing, into, my, ...         []   \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []   \n",
       "32  [i, could, however, see, that, his, face, was,...  [沽ｭ, 沽ｭ, 沽ｭ]   \n",
       "33                              [missed, video, call]         []   \n",
       "34                              [missed, voice, call]         []   \n",
       "\n",
       "    text_str_length msg_type  \n",
       "30               48     text  \n",
       "31               84     text  \n",
       "32               88     text  \n",
       "33               17     text  \n",
       "34               17     text  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video []\n"
     ]
    }
   ],
   "source": [
    "print(messages['msg_type'].iloc[10], messages['text_processed'].iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** <br>\n",
    "Next, let's [normalize](https://github.com/EFord36/normalise) our corpus to get rid of any spelling errors for common words. \n",
    "\n",
    "<br> **Note:** we can also leverage this to define a custom dictionary of common 'chat-specific' slang. The intent is to clump together similar words as much as possible (for example, treating *'lol'* and *'loool'* as the same word *'lol'*. The default `normalise()` method appears to handle cases of formal English words with repeated single characters well, such as the previous example. However, we need to add the 'root' slang to the [custom abbreviation dictionary](https://towardsdatascience.com/nlp-text-preprocessing-and-cleaning-pipeline-in-python-3bafaf54ac35) since it attempts to change the root words to a 'correct' English word. So **YMMV** based on the amount and complexity of slang in the message corpus.\n",
    "\n",
    "<br> **Update 01APR20: `normalize` was dropped since performance was abysmal, made my own customized slang normalization function instead.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 'Custom' normalizer:\n",
    "\n",
    "# 1) Define sets of 'slang' strings based on type of expected non-normalization, for example:\n",
    "# --- end-letter repeats (omgggg -> omg)\n",
    "# --- mid-letter repeats (looool -> lol)         [implemented via separate 'custom' dict instead]\n",
    "# --- combination repeats (wooowww -> wow)\n",
    "# --- two-letter repeats (hahahaha -> haha)      [implemented via separate 'custom' dict instead]\n",
    "# 2) Generate dicts which map slang variant to its 'root' form.\n",
    "# --- Will be specific for each set and have an 'upper bound' number of repeats\n",
    "# 3) Combine to a master 'normalization' dict. Define the custom normalization function to parse through the dict and evaluate feasibility of scaling up\n",
    "\n",
    "# Expected runtime O(n*m) where n = number of tokens in corpus, m = number of keys in master normalization lookup dict\n",
    "# Will be slow, but potentially m will at least 1-2 orders of magnitude smaller than using `normalise` library\n",
    "\n",
    "# Custom / User defined:\n",
    "# --- 'base' slang words and their 'type'\n",
    "# --- 'upper bound' on number of repeats for dict generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to generate dicts of slang strings based on their type\n",
    "def generate_slang_variants(slang_dict, LIMIT = 5):\n",
    "    \"\"\"\n",
    "    Input:    LIMIT:            Integer defining maximum number of repeated letters.\n",
    "                                Default is 5 (i.e, 5 repeated single / double letters in the variant)\n",
    "              slang_dict:       Dictionary of string: integer pairs.\n",
    "                                Strings are slang 'base' words. Integers are the slang variant 'type'defined below:\n",
    "                                1 == Repeating single final letter (eg. lmaooo -> lmao)\n",
    "                                2 == Repeating double final letters (eg. wooowww -> wow)\n",
    "                                \n",
    "    Output:   slang_lookup:     Dictionary of slang-variant : slang-root pairs\n",
    "    \"\"\"\n",
    "    slang_lookup = {}\n",
    "    \n",
    "    for root in slang_dict: #root[-2:]\n",
    "                \n",
    "        if slang_dict[root] == 1:\n",
    "            # Case 1: Repeat the single final letter up to limit. Add to final dictionary with root as value\n",
    "            for i in range(LIMIT):\n",
    "                variant = root + (root[-1]*i)\n",
    "                slang_lookup.update({variant : root})\n",
    "            \n",
    "        elif slang_dict[root] == 2:\n",
    "            # Case 2: Generate combinations of both final letters up to limit. Add to final dictionary with root as value\n",
    "            for i in range(1, LIMIT+1):\n",
    "                for j in range(1, LIMIT+1):\n",
    "                    variant = root[:-2] + (root[-2]*i) + (root[-1]*j)\n",
    "                    slang_lookup.update({variant : root})\n",
    "    \n",
    "    return slang_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary function to normalize slang variants to their 'base' slang form\n",
    "def normalize_slang(tokenlist, slang_lookup):\n",
    "    \"\"\"\n",
    "    Input:    tokenlist:    Tokenized corpus to be parsed and normalized\n",
    "              slang_lookup: Dictionary of slang-variant : slang-root pairs\n",
    "\n",
    "    Output:   tokenlist_normalized:    Normalized, tokenized corpus\n",
    "    \"\"\"\n",
    "    tokenlist_normalized = []\n",
    "    \n",
    "    for token in tokenlist:\n",
    "        if token in slang_lookup:\n",
    "            tokenlist_normalized.append(slang_lookup[token])\n",
    "        else:\n",
    "            tokenlist_normalized.append(token)\n",
    "    \n",
    "    return tokenlist_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hah', 'lmaoooo', 'wooowww']\n"
     ]
    }
   ],
   "source": [
    "testmessage = messages['text_processed'].iloc[3]\n",
    "print(testmessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lmao': 'lmao', 'lmaoo': 'lmao', 'lmaooo': 'lmao', 'lmaoooo': 'lmao', 'lmaooooo': 'lmao', 'wow': 'wow', 'woww': 'wow', 'wowww': 'wow', 'wowwww': 'wow', 'wowwwww': 'wow', 'woow': 'wow', 'wooww': 'wow', 'woowww': 'wow', 'woowwww': 'wow', 'woowwwww': 'wow', 'wooow': 'wow', 'woooww': 'wow', 'wooowww': 'wow', 'wooowwww': 'wow', 'wooowwwww': 'wow', 'woooow': 'wow', 'wooooww': 'wow', 'woooowww': 'wow', 'woooowwww': 'wow', 'woooowwwww': 'wow', 'wooooow': 'wow', 'woooooww': 'wow', 'wooooowww': 'wow', 'wooooowwww': 'wow', 'wooooowwwww': 'wow', 'ha': 'hahaha', 'hah': 'hahaha', 'haha': 'hahaha'}\n"
     ]
    }
   ],
   "source": [
    "# Generate final dictionary mapping slang variants to their 'base' slang word.\n",
    "slang_lookup = generate_slang_variants(slang_dict, VARIANT_LIMIT)\n",
    "\n",
    "# 'Custom' slang variants are added to this final dictionary as well\n",
    "slang_lookup.update(slang_special_cases)\n",
    "print(slang_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hahaha', 'lmao', 'wow']\n"
     ]
    }
   ],
   "source": [
    "testmessage_norm = normalize_slang(testmessage, slang_lookup)\n",
    "print(testmessage_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>but the sudden glare flashing into my weary eyes</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[but, the, sudden, glare, flashing, into, my, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, it, impossible, for, me, to, tell, what...</td>\n",
       "      <td>[]</td>\n",
       "      <td>84</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[i, could, however, see, that, his, face, was,...</td>\n",
       "      <td>[沽ｭ, 沽ｭ, 沽ｭ]</td>\n",
       "      <td>88</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>窶皿issed video call</td>\n",
       "      <td>2020-03-08 18:20:13-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[missed, video, call]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>窶皿issed voice call</td>\n",
       "      <td>2020-03-08 18:22:23-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[missed, voice, call]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "30   but the sudden glare flashing into my weary eyes   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33                                 窶皿issed video call   \n",
       "34                                 窶皿issed voice call   \n",
       "\n",
       "                   date_time username  \\\n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 18:20:13-04:00   User 2   \n",
       "34 2020-03-08 18:22:23-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis  \\\n",
       "30  [but, the, sudden, glare, flashing, into, my, ...         []   \n",
       "31  [made, it, impossible, for, me, to, tell, what...         []   \n",
       "32  [i, could, however, see, that, his, face, was,...  [沽ｭ, 沽ｭ, 沽ｭ]   \n",
       "33                              [missed, video, call]         []   \n",
       "34                              [missed, voice, call]         []   \n",
       "\n",
       "    text_str_length msg_type  \n",
       "30               48     text  \n",
       "31               84     text  \n",
       "32               88     text  \n",
       "33               17     text  \n",
       "34               17     text  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_processed'] = messages['text_processed'].apply(lambda x: normalize_slang(x, slang_lookup))\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:**<br>\n",
    "Next, let's remove common [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) from our tokenized corpus. **Note:** Our helper function will also turn our text to all lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'how', 'than', \"should've\", 't', 'doesn', 'some', 'yours', 'only', 'needn', 'his', 'their', 'now', 'her', \"hadn't\", \"hasn't\", 'am', 'a', 'is', 'shouldn', 'you', 's', \"she's\", 'yourself', 'be', 'if', 'll', 'further', 'while', 'ma', 'after', 'theirs', 'we', 'in', 'both', \"mightn't\", 'herself', 'so', 'themselves', 'during', 'once', 'its', 'myself', \"weren't\", 'hadn', 'most', \"you've\", 'against', 'all', \"doesn't\", 'him', 'itself', 'do', 'own', 'wasn', 'they', 'it', 'nor', 'those', \"isn't\", 'isn', 'couldn', 'more', 'didn', 'm', 'mustn', 'weren', 'have', 'me', 'been', 'between', 'will', 'y', \"wasn't\", 'each', 'not', \"you're\", \"you'll\", 'being', 'before', \"couldn't\", 'by', 'did', 'where', \"wouldn't\", 'haven', 'at', 'that', 'then', 'as', \"didn't\", 'or', 're', 'he', 'no', 'having', 'into', 'yourselves', 'with', 'any', 'ours', 'were', 'these', 'o', 'our', \"that'll\", 'when', 'again', \"won't\", 'mightn', 'but', 'on', \"mustn't\", 'she', 'don', 'down', 've', 'i', 'should', 'does', 'few', 'from', 'whom', 'what', 'under', 'won', 'below', 'above', 'and', 'too', 'there', 'hasn', \"aren't\", \"needn't\", 'an', 'wouldn', 'through', 'out', 'who', 'the', 'off', 'over', 'here', \"you'd\", 'was', 'such', 'my', 'can', 'other', 'same', 'himself', 'to', \"shouldn't\", 'had', 'up', 'd', \"it's\", 'about', \"haven't\", 'them', \"don't\", 'until', 'just', 'hers', 'ourselves', 'your', 'shan', 'doing', 'this', 'ain', 'has', \"shan't\", 'of', 'which', 'for', 'aren', 'because', 'very', 'why', 'are'}\n"
     ]
    }
   ],
   "source": [
    "# Define list of stopwords\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "print(stopwords_list)\n",
    "\n",
    "# List comprehension helper function to remove stopwords\n",
    "def remove_stopwords(tokenlist):\n",
    "    return [word.lower() for word in tokenlist if word.lower() not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_raw</th>\n",
       "      <th>date_time</th>\n",
       "      <th>username</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>emojis</th>\n",
       "      <th>text_str_length</th>\n",
       "      <th>msg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>but the sudden glare flashing into my weary eyes</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[sudden, glare, flashing, weary, eyes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>made it impossible for me to tell what it was ...</td>\n",
       "      <td>2020-03-08 17:45:56-04:00</td>\n",
       "      <td>User 1</td>\n",
       "      <td>[made, impossible, tell, friend, lashed, savag...</td>\n",
       "      <td>[]</td>\n",
       "      <td>84</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I could, however, see that his face was deadly...</td>\n",
       "      <td>2020-03-08 17:50:34-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[could, however, see, face, deadly, pale, fill...</td>\n",
       "      <td>[沽ｭ, 沽ｭ, 沽ｭ]</td>\n",
       "      <td>88</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>窶皿issed video call</td>\n",
       "      <td>2020-03-08 18:20:13-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[missed, video, call]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>窶皿issed voice call</td>\n",
       "      <td>2020-03-08 18:22:23-04:00</td>\n",
       "      <td>User 2</td>\n",
       "      <td>[missed, voice, call]</td>\n",
       "      <td>[]</td>\n",
       "      <td>17</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_raw  \\\n",
       "30   but the sudden glare flashing into my weary eyes   \n",
       "31  made it impossible for me to tell what it was ...   \n",
       "32  I could, however, see that his face was deadly...   \n",
       "33                                 窶皿issed video call   \n",
       "34                                 窶皿issed voice call   \n",
       "\n",
       "                   date_time username  \\\n",
       "30 2020-03-08 17:45:56-04:00   User 1   \n",
       "31 2020-03-08 17:45:56-04:00   User 1   \n",
       "32 2020-03-08 17:50:34-04:00   User 2   \n",
       "33 2020-03-08 18:20:13-04:00   User 2   \n",
       "34 2020-03-08 18:22:23-04:00   User 2   \n",
       "\n",
       "                                       text_processed     emojis  \\\n",
       "30             [sudden, glare, flashing, weary, eyes]         []   \n",
       "31  [made, impossible, tell, friend, lashed, savag...         []   \n",
       "32  [could, however, see, face, deadly, pale, fill...  [沽ｭ, 沽ｭ, 沽ｭ]   \n",
       "33                              [missed, video, call]         []   \n",
       "34                              [missed, voice, call]         []   \n",
       "\n",
       "    text_str_length msg_type  \n",
       "30               48     text  \n",
       "31               84     text  \n",
       "32               88     text  \n",
       "33               17     text  \n",
       "34               17     text  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['text_processed'] = messages['text_processed'].apply(remove_stopwords)\n",
    "messages.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lmao      5\n",
       "hahaha    4\n",
       "heard     3\n",
       "see       3\n",
       "sound     3\n",
       "Name: text_processed, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_processed_master = messages['text_processed'].explode().value_counts()\n",
    "text_processed_master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "沽ｯ    11\n",
       "沽ｭ     7\n",
       "沽     2\n",
       "汨     2\n",
       "笘ｺ     2\n",
       "Name: emojis, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_master = messages['emojis'].explode().value_counts()\n",
    "emoji_master.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:datasciproj]",
   "language": "python",
   "name": "conda-env-datasciproj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
